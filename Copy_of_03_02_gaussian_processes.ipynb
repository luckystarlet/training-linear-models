{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luckystarlet/training-linear-models/blob/main/Copy_of_03_02_gaussian_processes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKGGzosAUsxI"
      },
      "source": [
        "# Gaussian Processes\n",
        "\n",
        "### 2025-09-16"
      ],
      "id": "VKGGzosAUsxI"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pWha8_JUsxK"
      },
      "source": [
        "**Abstract**: null"
      ],
      "id": "_pWha8_JUsxK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzGjYr3TUsxK"
      },
      "source": [
        "$$\n",
        "$$"
      ],
      "id": "yzGjYr3TUsxK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnat7DoDUsxK"
      },
      "source": [
        "<!-- Do not edit this file locally. -->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!---->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!-- Do not edit this file locally. -->\n",
        "<!-- The last names to be defined. Should be defined entirely in terms of macros from above-->\n",
        "<!--\n",
        "\n",
        "-->"
      ],
      "id": "gnat7DoDUsxK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gePBJBsUsxL"
      },
      "source": [
        "## ML Foundations Course Notebook Setup\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_mlfc/includes/mlfc-notebook-setup.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_mlfc/includes/mlfc-notebook-setup.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "We install some bespoke codes for creating and saving plots as well as\n",
        "loading data sets."
      ],
      "id": "4gePBJBsUsxL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mD1ljY3EUsxL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install notutils\n",
        "%pip install pods\n",
        "%pip install mlai"
      ],
      "id": "mD1ljY3EUsxL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yyx1G8_UsxM"
      },
      "outputs": [],
      "source": [
        "import notutils\n",
        "import pods\n",
        "import mlai\n",
        "import mlai.plot as plot"
      ],
      "id": "3yyx1G8_UsxM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pfvxtJiIUsxM"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams.update({'font.size': 22})"
      ],
      "id": "pfvxtJiIUsxM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWeUT1HAUsxM"
      },
      "source": [
        "<!--setupplotcode{import seaborn as sns\n",
        "sns.set_style('darkgrid')\n",
        "sns.set_context('paper')\n",
        "sns.set_palette('colorblind')}-->"
      ],
      "id": "HWeUT1HAUsxM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVVB_OdTUsxN"
      },
      "source": [
        "## Review\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/gaussian-processes.gpp.markdown\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/gaussian-processes.gpp.markdown', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Over the last two sessions we’ve begun considering classification models\n",
        "and logistic regresssion. In particular, for naive Bayes, we considered\n",
        "a set of assumptions that allowed us to build a joint model of our data\n",
        "set. In particular for naive Bayes we specified\n",
        "\n",
        "1.  Data conditional independence.\n",
        "2.  Feature conditional independence.\n",
        "3.  Marginal likelihood of labels was Bernoulli distributed.\n",
        "\n",
        "This allowed us to specify the joint density of our labels and our input\n",
        "data, $p(\\mathbf{ y}, \\mathbf{X}|\\boldsymbol{\\theta})$. And we\n",
        "conditioned on the training data to make predictions about the test\n",
        "data."
      ],
      "id": "iVVB_OdTUsxN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkTHzcNoUsxN"
      },
      "source": [
        "## Generalized Linear Models\n",
        "\n",
        "Logistic regression is part of a wider class of models known as\n",
        "*generalized linear models*. In these models we determine that some\n",
        "characteristic of the model is speicified by a function that is liniear\n",
        "in the parameters. So we might suggest that $$\n",
        "\\log \\frac{p(\\mathbf{ x})}{1-p(\\mathbf{ x})} = f(\\mathbf{ x}; \\mathbf{ w})\n",
        "$$ where $f(\\mathbf{ x}; \\mathbf{ w})$ is a linear-in-the-parameters\n",
        "function (here the parameters are $\\mathbf{ w}$, which is generally\n",
        "non-linear in the inputs.\n",
        "\n",
        "So far we have considered basis function models of the form\n",
        "\n",
        "$$\n",
        "f(\\mathbf{ x}) =\n",
        "\\mathbf{ w}^\\top \\boldsymbol{ \\phi}(\\mathbf{ x}).\n",
        "$$ When we form a Gaussian process we do something that is slightly more\n",
        "akin to the naive Bayes approach, but actually is closely related to the\n",
        "generalized linear model approach."
      ],
      "id": "IkTHzcNoUsxN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zr4A9P3DUsxN"
      },
      "source": [
        "## Gaussian Processes\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-intro-lectures.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-intro-lectures.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Models where we model the entire joint distribution of our training\n",
        "data, $p(\\mathbf{ y}, \\mathbf{X})$ are sometimes described as\n",
        "*generative models*. Because we can use sampling to generate data sets\n",
        "that represent all our assumptions. However, as we discussed in the\n",
        "sessions on and , this can be a bad idea, because if our assumptions are\n",
        "wrong then we can make poor predictions. We can try to make more complex\n",
        "assumptions about data to alleviate the problem, but then this typically\n",
        "leads to challenges for tractable application of the sum and rules of\n",
        "probability that are needed to compute the relevant marginal and\n",
        "conditional densities. If we know the form of the question we wish to\n",
        "answer then we typically try and represent that directly, through\n",
        "$p(\\mathbf{ y}|\\mathbf{X})$. In practice, we also have been making\n",
        "assumptions of conditional independence given the model parameters, $$\n",
        "p(\\mathbf{ y}|\\mathbf{X}, \\mathbf{ w}) =\n",
        "\\prod_{i=1}^{n} p(y_i | \\mathbf{ x}_i, \\mathbf{ w})\n",
        "$$ Gaussian processes are *not* normally considered to be *generative\n",
        "models*, but we will be much more interested in the principles of\n",
        "conditioning in Gaussian processes because we will use conditioning to\n",
        "make predictions between our test and training data. We will avoid the\n",
        "data conditional indpendence assumption in favour of a richer assumption\n",
        "about the data, in a Gaussian process we assume data is *jointly\n",
        "Gaussian* with a particular mean and covariance, $$\n",
        "\\mathbf{ y}|\\mathbf{X}\\sim \\mathcal{N}\\left(\\mathbf{m}(\\mathbf{X}),\\mathbf{K}(\\mathbf{X})\\right),\n",
        "$$ where the conditioning is on the inputs $\\mathbf{X}$ which are used\n",
        "for computing the mean and covariance. For this reason they are known as\n",
        "mean and covariance functions."
      ],
      "id": "zr4A9P3DUsxN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nm3b8TBKUsxO"
      },
      "source": [
        "## Prediction Across Two Points with GPs\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gptwopointpred.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gptwopointpred.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
      ],
      "id": "Nm3b8TBKUsxO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCXGz796UsxO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(4949)"
      ],
      "id": "PCXGz796UsxO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ac3fJLrXUsxO"
      },
      "outputs": [],
      "source": [
        "import mlai.plot as plot\n",
        "import pods"
      ],
      "id": "ac3fJLrXUsxO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KXQKlIQiUsxO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(4949)"
      ],
      "id": "KXQKlIQiUsxO"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_-tX8vfUsxO"
      },
      "source": [
        "## Sampling a Function\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gpdistfunc.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gpdistfunc.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "We will consider a Gaussian distribution with a particular structure of\n",
        "covariance matrix. We will generate *one* sample from a 25-dimensional\n",
        "Gaussian density. $$\n",
        "\\mathbf{ f}=\\left[f_{1},f_{2}\\dots f_{25}\\right].\n",
        "$$ in the figure below we plot these data on the $y$-axis against their\n",
        "*indices* on the $x$-axis."
      ],
      "id": "W_-tX8vfUsxO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uvF_GPKyUsxP"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "uvF_GPKyUsxP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rAf2_PuCUsxP"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.Kernel"
      ],
      "id": "rAf2_PuCUsxP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hi7uIbSUsxP"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "5hi7uIbSUsxP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NDnaatdIUsxP"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.polynomial_cov"
      ],
      "id": "NDnaatdIUsxP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MLcEcg9UsxP"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "5MLcEcg9UsxP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB2mC7GdUsxP"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.exponentiated_quadratic"
      ],
      "id": "ZB2mC7GdUsxP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lYZHp1SfUsxP"
      },
      "outputs": [],
      "source": [
        "import mlai.plot as plot\n",
        "from mlai import Kernel, exponentiated_quadratic"
      ],
      "id": "lYZHp1SfUsxP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxbuSztaUsxQ"
      },
      "outputs": [],
      "source": [
        "kernel=Kernel(function=exponentiated_quadratic, lengthscale=0.5)\n",
        "plot.two_point_sample(kernel.K, diagrams='./gp')"
      ],
      "id": "xxbuSztaUsxQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yoW49hDUsxQ"
      },
      "outputs": [],
      "source": [
        "import notutils as nu\n",
        "from ipywidgets import IntSlider"
      ],
      "id": "6yoW49hDUsxQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uEGegMqeUsxQ"
      },
      "outputs": [],
      "source": [
        "import notutils as nu"
      ],
      "id": "uEGegMqeUsxQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8n0o7uKQUsxQ"
      },
      "outputs": [],
      "source": [
        "nu.display_plots('two_point_sample{sample:0>3}.svg', './gp', sample=IntSlider(0, 0, 8, 1))"
      ],
      "id": "8n0o7uKQUsxQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu2WZNz5UsxQ"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/two_point_sample008.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>A 25 dimensional correlated random variable (values ploted\n",
        "against index)</i>"
      ],
      "id": "wu2WZNz5UsxQ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ka9rRZ1VUsxQ"
      },
      "source": [
        "### Sampling a Function from a Gaussian\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gaussian-predict-index-one-and-two.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gaussian-predict-index-one-and-two.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
      ],
      "id": "ka9rRZ1VUsxQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEHUw5H4UsxQ"
      },
      "outputs": [],
      "source": [
        "import notutils as nu\n",
        "from ipywidgets import IntSlider"
      ],
      "id": "HEHUw5H4UsxQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfuqrWbiUsxR"
      },
      "outputs": [],
      "source": [
        "import notutils as nu"
      ],
      "id": "xfuqrWbiUsxR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VisKQsVUsxR"
      },
      "outputs": [],
      "source": [
        "nu.display_plots('two_point_sample{sample:0>3}.svg',\n",
        "                            './gp',\n",
        "                            sample=IntSlider(0, 0, 8, 1))"
      ],
      "id": "9VisKQsVUsxR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DB2QJHSVUsxR"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/two_point_sample001.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>The joint Gaussian over $f_1$ and $f_2$ along with the\n",
        "conditional distribution of $f_2$ given $f_1$</i>"
      ],
      "id": "DB2QJHSVUsxR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqdhA8dkUsxR"
      },
      "source": [
        "### Joint Density of $f_1$ and $f_2$"
      ],
      "id": "pqdhA8dkUsxR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfRXoAj3UsxR"
      },
      "outputs": [],
      "source": [
        "import notutils as nu\n",
        "from ipywidgets import IntSlider"
      ],
      "id": "tfRXoAj3UsxR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzC83Wv7UsxS"
      },
      "outputs": [],
      "source": [
        "import notutils as nu"
      ],
      "id": "PzC83Wv7UsxS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOP_FEQNUsxS"
      },
      "outputs": [],
      "source": [
        "nu.display_plots('two_point_sample{sample:0>3}.svg',\n",
        "                            './gp',\n",
        "                            sample=IntSlider(9, 9, 12, 1))"
      ],
      "id": "jOP_FEQNUsxS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RB5qfKsfUsxS"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/two_point_sample012.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>The joint Gaussian over $f_1$ and $f_2$ along with the\n",
        "conditional distribution of $f_2$ given $f_1$</i>"
      ],
      "id": "RB5qfKsfUsxS"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtnIBIUJUsxX"
      },
      "source": [
        "## Uluru\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/799px-Uluru_Panorama.jpg\" style=\"width:\">\n",
        "\n",
        "Figure: <i>Uluru, the sacred rock in Australia. If we think of it as a\n",
        "probability density, viewing it from this side gives us one *marginal*\n",
        "from the density. Figuratively speaking, slicing through the rock would\n",
        "give a conditional density.</i>\n",
        "\n",
        "When viewing these contour plots, I sometimes find it helpful to think\n",
        "of Uluru, the prominent rock formation in Australia. The rock rises\n",
        "above the surface of the plane, just like a probability density rising\n",
        "above the zero line. The rock is three dimensional, but when we view\n",
        "Uluru from the classical position, we are looking at one side of it.\n",
        "This is equivalent to viewing the marginal density.\n",
        "\n",
        "The joint density can be viewed from above, using contours. The\n",
        "conditional density is equivalent to *slicing* the rock. Uluru is a holy\n",
        "rock, so this has to be an imaginary slice. Imagine we cut down a\n",
        "vertical plane orthogonal to our view point (e.g. coming across our view\n",
        "point). This would give a profile of the rock, which when renormalized,\n",
        "would give us the conditional distribution, the value of conditioning\n",
        "would be the location of the slice in the direction we are facing."
      ],
      "id": "jtnIBIUJUsxX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbgVHUlBUsxX"
      },
      "source": [
        "## Prediction with Correlated Gaussians\n",
        "\n",
        "Of course in practice, rather than manipulating mountains physically,\n",
        "the advantage of the Gaussian density is that we can perform these\n",
        "manipulations mathematically.\n",
        "\n",
        "Prediction of $f_2$ given $f_1$ requires the *conditional density*,\n",
        "$p(f_2|f_1)$.Another remarkable property of the Gaussian density is that\n",
        "this conditional distribution is *also* guaranteed to be a Gaussian\n",
        "density. It has the form, $$\n",
        "p(f_2|f_1) = \\mathcal{N}\\left(f_2|\\frac{k_{1, 2}}{k_{1, 1}}f_1, k_{2, 2} - \\frac{k_{1,2}^2}{k_{1,1}}\\right)\n",
        "$$where we have assumed that the covariance of the original joint\n",
        "density was given by $$\n",
        "\\mathbf{K}= \\begin{bmatrix} k_{1, 1} & k_{1, 2}\\\\ k_{2, 1} & k_{2, 2}.\\end{bmatrix}\n",
        "$$\n",
        "\n",
        "Using these formulae we can determine the conditional density for any of\n",
        "the elements of our vector $\\mathbf{ f}$. For example, the variable\n",
        "$f_8$ is less correlated with $f_1$ than $f_2$. If we consider this\n",
        "variable we see the conditional density is more diffuse."
      ],
      "id": "ZbgVHUlBUsxX"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "614BYofNUsxX"
      },
      "source": [
        "### Joint Density of $f_1$ and $f_8$\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gaussian-predict-index-one-and-eight.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gaussian-predict-index-one-and-eight.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
      ],
      "id": "614BYofNUsxX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "if_Om1OlUsxY"
      },
      "outputs": [],
      "source": [
        "import notutils as nu\n",
        "from ipywidgets import IntSlider"
      ],
      "id": "if_Om1OlUsxY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iYjwk1hIUsxY"
      },
      "outputs": [],
      "source": [
        "import notutils as nu"
      ],
      "id": "iYjwk1hIUsxY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEAOOUaOUsxY"
      },
      "outputs": [],
      "source": [
        "nu.display_plots('two_point_sample{sample:0>3}.svg',\n",
        "                            './gp',\n",
        "                            sample=IntSlider(13, 13, 17, 1))"
      ],
      "id": "LEAOOUaOUsxY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2zJKz9aUsxY"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/two_point_sample013.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>Sample from the joint Gaussian model, points indexed by 1 and\n",
        "8 highlighted.</i>"
      ],
      "id": "w2zJKz9aUsxY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YquWsB3mUsxY"
      },
      "source": [
        "### Prediction of $f_{8}$ from $f_{1}$\n",
        "\n",
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/two_point_sample017.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>The joint Gaussian over $f_1$ and $f_8$ along with the\n",
        "conditional distribution of $f_8$ given $f_1$</i>\n",
        "\n",
        "-   The single contour of the Gaussian density represents the\n",
        "    <font color=\"blue\">joint distribution, $p(f_1, f_8)$</font>\n",
        "\n",
        ". . .\n",
        "\n",
        "-   We observe a value for <font color=\"green\">$f_1=-?$</font>\n",
        "\n",
        ". . .\n",
        "\n",
        "-   Conditional density: <font color=\"red\">$p(f_8|f_1=?)$</font>.\n",
        "\n",
        "-   Prediction of $\\mathbf{ f}_*$ from $\\mathbf{ f}$ requires\n",
        "    multivariate *conditional density*.\n",
        "\n",
        "-   Multivariate conditional density is *also* Gaussian. <large> $$\n",
        "    p(\\mathbf{ f}_*|\\mathbf{ f}) = {\\mathcal{N}\\left(\\mathbf{ f}_*|\\mathbf{K}_{*,\\mathbf{ f}}\\mathbf{K}_{\\mathbf{ f},\\mathbf{ f}}^{-1}\\mathbf{ f},\\mathbf{K}_{*,*}-\\mathbf{K}_{*,\\mathbf{ f}} \\mathbf{K}_{\\mathbf{ f},\\mathbf{ f}}^{-1}\\mathbf{K}_{\\mathbf{ f},*}\\right)}\n",
        "    $$ </large>\n",
        "\n",
        "-   Here covariance of joint density is given by $$\n",
        "    \\mathbf{K}= \\begin{bmatrix} \\mathbf{K}_{\\mathbf{ f}, \\mathbf{ f}} & \\mathbf{K}_{*, \\mathbf{ f}}\\\\ \\mathbf{K}_{\\mathbf{ f}, *} & \\mathbf{K}_{*, *}\\end{bmatrix}\n",
        "    $$\n",
        "\n",
        "-   Prediction of $\\mathbf{ f}_*$ from $\\mathbf{ f}$ requires\n",
        "    multivariate *conditional density*.\n",
        "\n",
        "-   Multivariate conditional density is *also* Gaussian. <large> $$\n",
        "    p(\\mathbf{ f}_*|\\mathbf{ f}) = {\\mathcal{N}\\left(\\mathbf{ f}_*|\\boldsymbol{ \\mu},\\boldsymbol{ \\Sigma}\\right)}\n",
        "    $$ $$\n",
        "    \\boldsymbol{ \\mu}= \\mathbf{K}_{*,\\mathbf{ f}}\\mathbf{K}_{\\mathbf{ f},\\mathbf{ f}}^{-1}\\mathbf{ f}\n",
        "    $$ $$\n",
        "    \\boldsymbol{ \\Sigma}= \\mathbf{K}_{*,*}-\\mathbf{K}_{*,\\mathbf{ f}} \\mathbf{K}_{\\mathbf{ f},\\mathbf{ f}}^{-1}\\mathbf{K}_{\\mathbf{ f},*}\n",
        "    $$ </large>\n",
        "\n",
        "-   Here covariance of joint density is given by $$\n",
        "    \\mathbf{K}= \\begin{bmatrix} \\mathbf{K}_{\\mathbf{ f}, \\mathbf{ f}} & \\mathbf{K}_{*, \\mathbf{ f}}\\\\ \\mathbf{K}_{\\mathbf{ f}, *} & \\mathbf{K}_{*, *}\\end{bmatrix}\n",
        "    $$"
      ],
      "id": "YquWsB3mUsxY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVG70Be-UsxY"
      },
      "source": [
        "## Marginal Likelihood\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-from-basis-functions.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-from-basis-functions.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "To understand the Gaussian process we’re going to build on our\n",
        "understanding of the marginal likelihood for Bayesian regression. In the\n",
        "session on we sampled directly from the weight vector, $\\mathbf{ w}$ and\n",
        "applied it to the basis matrix $\\boldsymbol{ \\Phi}$ to obtain a sample\n",
        "from the prior and a sample from the posterior. It is often helpful to\n",
        "think of modeling techniques as *generative* models. To give some\n",
        "thought as to what the process for obtaining data from the model is.\n",
        "From the perspective of Gaussian processes, we want to start by thinking\n",
        "of basis function models, where the parameters are sampled from a prior,\n",
        "but move to thinking about sampling from the marginal likelihood\n",
        "directly."
      ],
      "id": "kVG70Be-UsxY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUcJpunIUsxZ"
      },
      "source": [
        "## Sampling from the Prior\n",
        "\n",
        "The first thing we’ll do is to set up the parameters of the model, these\n",
        "include the parameters of the prior, the parameters of the basis\n",
        "functions and the noise level."
      ],
      "id": "cUcJpunIUsxZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JW_48k0vUsxZ"
      },
      "outputs": [],
      "source": [
        "# set prior variance on w\n",
        "alpha = 4.\n",
        "# set the order of the polynomial basis set\n",
        "degree = 5\n",
        "# set the noise variance\n",
        "sigma2 = 0.01"
      ],
      "id": "JW_48k0vUsxZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upinEsMZUsxZ"
      },
      "source": [
        "Now we have the variance, we can sample from the prior distribution to\n",
        "see what form we are imposing on the functions *a priori*.\n",
        "\n",
        "Let’s now compute a range of values to make predictions at, spanning the\n",
        "*new* space of inputs,"
      ],
      "id": "upinEsMZUsxZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ae6e4mFdUsxZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ],
      "id": "Ae6e4mFdUsxZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ifpkDde8UsxZ"
      },
      "outputs": [],
      "source": [
        "def polynomial(x, degree, loc, scale):\n",
        "    degrees = np.arange(degree+1)\n",
        "    return ((x-loc)/scale)**degrees"
      ],
      "id": "ifpkDde8UsxZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BGBLR0KUsxZ"
      },
      "source": [
        "now let’s build the basis matrices. First we load in the data"
      ],
      "id": "0BGBLR0KUsxZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8Y15eD6Usxa"
      },
      "outputs": [],
      "source": [
        "import pods"
      ],
      "id": "i8Y15eD6Usxa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzaeTu2fUsxa"
      },
      "outputs": [],
      "source": [
        "data = pods.datasets.olympic_marathon_men()\n",
        "x = data['X']\n",
        "y = data['Y']"
      ],
      "id": "KzaeTu2fUsxa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GK2LawcVUsxa"
      },
      "outputs": [],
      "source": [
        "loc = 1950.\n",
        "scale = 100.\n",
        "num_data = x.shape[0]\n",
        "num_pred_data = 100 # how many points to use for plotting predictions\n",
        "x_pred = np.linspace(1880, 2030, num_pred_data)[:, np.newaxis] # input locations for predictions\n",
        "Phi_pred = polynomial(x_pred, degree=degree, loc=loc, scale=scale)\n",
        "Phi = polynomial(x, degree=degree, loc=loc, scale=scale)"
      ],
      "id": "GK2LawcVUsxa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H0IY-VMUsxa"
      },
      "source": [
        "## Weight Space View\n",
        "\n",
        "To generate typical functional predictions from the model, we need a set\n",
        "of model parameters. We assume that the parameters are drawn\n",
        "independently from a Gaussian density, $$\n",
        "\\mathbf{ w}\\sim \\mathcal{N}\\left(\\mathbf{0},\\alpha\\mathbf{I}\\right),\n",
        "$$ then we can combine this with the definition of our prediction\n",
        "function $f(\\mathbf{ x})$, $$\n",
        "f(\\mathbf{ x}) = \\mathbf{ w}^\\top \\boldsymbol{ \\phi}(\\mathbf{ x}).\n",
        "$$ We can now sample from the prior density to obtain a vector\n",
        "$\\mathbf{ w}$ using the function `np.random.normal` and combine these\n",
        "parameters with our basis to create some samples of what\n",
        "$f(\\mathbf{ x})$ looks like,"
      ],
      "id": "6H0IY-VMUsxa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fF4LBdd9Usxa"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "id": "fF4LBdd9Usxa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmW5C3AcUsxa"
      },
      "outputs": [],
      "source": [
        "num_samples = 10\n",
        "K = degree+1\n",
        "for i in range(num_samples):\n",
        "    z_vec = np.random.normal(size=(K, 1))\n",
        "    w_sample = z_vec*np.sqrt(alpha)\n",
        "    f_sample = Phi_pred@w_sample\n",
        "    plt.plot(x_pred, f_sample)"
      ],
      "id": "UmW5C3AcUsxa"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFu_8at1Usxb"
      },
      "source": [
        "## Function Space View\n",
        "\n",
        "The process we have used to generate the samples is a two stage process.\n",
        "To obtain each function, we first generated a sample from the prior, $$\n",
        "\\mathbf{ w}\\sim \\mathcal{N}\\left(\\mathbf{0},\\alpha \\mathbf{I}\\right)\n",
        "$$ then if we compose our basis matrix, $\\boldsymbol{ \\Phi}$ from the\n",
        "basis functions associated with each row then we get, $$\n",
        "\\boldsymbol{ \\Phi}= \\begin{bmatrix}\\boldsymbol{ \\phi}(\\mathbf{ x}_1) \\\\ \\vdots \\\\\n",
        "\\boldsymbol{ \\phi}(\\mathbf{ x}_n)\\end{bmatrix}\n",
        "$$ then we can write down the vector of function values, as evaluated at\n",
        "$$\n",
        "\\mathbf{ f}= \\begin{bmatrix} f_1\n",
        "\\\\ \\vdots f_n\\end{bmatrix}\n",
        "$$ in the form $$\n",
        "\\mathbf{ f}= \\boldsymbol{ \\Phi}\\mathbf{ w}.\n",
        "$$\n",
        "\n",
        "Now we can use standard properties of multivariate Gaussians to write\n",
        "down the probability density that is implied over $\\mathbf{ f}$. In\n",
        "particular we know that if $\\mathbf{ w}$ is sampled from a multivariate\n",
        "normal (or multivariate Gaussian) with covariance $\\alpha \\mathbf{I}$\n",
        "and zero mean, then assuming that $\\boldsymbol{ \\Phi}$ is a\n",
        "deterministic matrix (i.e. it is not sampled from a probability density)\n",
        "then the vector $\\mathbf{ f}$ will also be distributed according to a\n",
        "zero mean multivariate normal as follows, $$\n",
        "\\mathbf{ f}\\sim \\mathcal{N}\\left(\\mathbf{0},\\alpha \\boldsymbol{ \\Phi}\\boldsymbol{ \\Phi}^\\top\\right).\n",
        "$$\n",
        "\n",
        "The question now is, what happens if we sample $\\mathbf{ f}$ directly\n",
        "from this density, rather than first sampling $\\mathbf{ w}$ and then\n",
        "multiplying by $\\boldsymbol{ \\Phi}$. Let’s try this. First of all we\n",
        "define the covariance as $$\n",
        "\\mathbf{K}= \\alpha\n",
        "\\boldsymbol{ \\Phi}\\boldsymbol{ \\Phi}^\\top.\n",
        "$$"
      ],
      "id": "bFu_8at1Usxb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jrg01OJ8Usxb"
      },
      "outputs": [],
      "source": [
        "K = alpha*Phi_pred@Phi_pred.T"
      ],
      "id": "Jrg01OJ8Usxb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39_lcLUpUsxb"
      },
      "source": [
        "Now we can use the `np.random.multivariate_normal` command for sampling\n",
        "from a multivariate normal with covariance given by $\\mathbf{K}$ and\n",
        "zero mean,"
      ],
      "id": "39_lcLUpUsxb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-yH8SsiUsxc"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
        "for i in range(10):\n",
        "    f_sample = np.random.multivariate_normal(mean=np.zeros(x_pred.size), cov=K)\n",
        "    ax.plot(x_pred.flatten(), f_sample.flatten(), linewidth=2)\n",
        "\n",
        "mlai.write_figure('gp-sample-basis-function.svg', directory='./kern')"
      ],
      "id": "l-yH8SsiUsxc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adIW-vOQUsxc"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//kern/gp-sample-basis-function.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>Samples directly from the covariance function implied by the\n",
        "basis function based covariance,\n",
        "$\\alpha \\boldsymbol{ \\Phi}\\boldsymbol{ \\Phi}^\\top$.</i>\n",
        "\n",
        "The samples appear very similar to those which we obtained indirectly.\n",
        "That is no surprise because they are effectively drawn from the same\n",
        "mutivariate normal density. However, when sampling $\\mathbf{ f}$\n",
        "directly we created the covariance for $\\mathbf{ f}$. We can visualise\n",
        "the form of this covaraince in an image in python with a colorbar to\n",
        "show scale."
      ],
      "id": "adIW-vOQUsxc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-ralupnUsxc"
      },
      "outputs": [],
      "source": [
        "import mlai.plot as plot\n",
        "import mlai"
      ],
      "id": "A-ralupnUsxc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "it5TjOymUsxc"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=plot.big_figsize)\n",
        "im = ax.imshow(K, interpolation='none')\n",
        "fig.colorbar(im)\n",
        "\n",
        "mlai.write_figure('basis-covariance-function.svg', directory='./kern')"
      ],
      "id": "it5TjOymUsxc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiN-T_b_Usxd"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//kern/basis-covariance-function.svg\" class=\"\" width=\"60%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>Covariance of the function implied by the basis set\n",
        "$\\alpha\\boldsymbol{ \\Phi}\\boldsymbol{ \\Phi}^\\top$.</i>\n",
        "\n",
        "This image is the covariance expressed between different points on the\n",
        "function. In regression we normally also add independent Gaussian noise\n",
        "to obtain our observations $\\mathbf{ y}$, $$\n",
        "\\mathbf{ y}= \\mathbf{ f}+ \\boldsymbol{\\epsilon}\n",
        "$$ where the noise is sampled from an independent Gaussian distribution\n",
        "with variance $\\sigma^2$, $$\n",
        "\\epsilon \\sim \\mathcal{N}\\left(\\mathbf{0},\\sigma^2\\mathbf{I}\\right).\n",
        "$$ we can use properties of Gaussian variables, i.e. the fact that sum\n",
        "of two Gaussian variables is also Gaussian, and that it’s covariance is\n",
        "given by the sum of the two covariances, whilst the mean is given by the\n",
        "sum of the means, to write down the marginal likelihood, $$\n",
        "\\mathbf{ y}\\sim \\mathcal{N}\\left(\\mathbf{0},\\boldsymbol{ \\Phi}\\boldsymbol{ \\Phi}^\\top +\\sigma^2\\mathbf{I}\\right).\n",
        "$$ Sampling directly from this density gives us the noise corrupted\n",
        "functions,"
      ],
      "id": "qiN-T_b_Usxd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JV-UvJ43Usxd"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "JV-UvJ43Usxd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6NQbI742Usxe"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
        "K = alpha*Phi_pred@Phi_pred.T + sigma2*np.eye(x_pred.size)\n",
        "for i in range(10):\n",
        "    y_sample = np.random.multivariate_normal(mean=np.zeros(x_pred.size), cov=K)\n",
        "    ax.plot(x_pred.flatten(), y_sample.flatten())\n",
        "\n",
        "mlai.write_figure('gp-sample-basis-function-plus-noise.svg',\n",
        "                  directory='./kern')"
      ],
      "id": "6NQbI742Usxe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xpd7K0aEUsxe"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//kern/gp-sample-basis-function-plus-noise.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>Samples directly from the covariance function implied by the\n",
        "noise corrupted basis function based covariance,\n",
        "$\\alpha \\boldsymbol{ \\Phi}\\boldsymbol{ \\Phi}^\\top + \\sigma^2 \\mathbf{I}$.</i>\n",
        "\n",
        "where the effect of our noise term is to roughen the sampled functions,\n",
        "we can also increase the variance of the noise to see a different\n",
        "effect,"
      ],
      "id": "Xpd7K0aEUsxe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtoZC8RGUsxe"
      },
      "outputs": [],
      "source": [
        "sigma2 = 1.\n",
        "K = alpha*Phi_pred@Phi_pred.T + sigma2*np.eye(x_pred.size)"
      ],
      "id": "KtoZC8RGUsxe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y183yYxNUsxf"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
        "for i in range(10):\n",
        "    y_sample = np.random.multivariate_normal(mean=np.zeros(x_pred.size), cov=K)\n",
        "    plt.plot(x_pred.flatten(), y_sample.flatten())\n",
        "\n",
        "mlai.write_figure('gp-sample-basis-function-plus-large-noise.svg',\n",
        "                  directory='./kern')"
      ],
      "id": "y183yYxNUsxf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwVMWViRUsxf"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//kern/gp-sample-basis-function-plus-large-noise.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>Samples directly from the covariance function implied by the\n",
        "noise corrupted basis function based covariance,\n",
        "$\\alpha \\boldsymbol{ \\Phi}\\boldsymbol{ \\Phi}^\\top + \\mathbf{I}$.</i>"
      ],
      "id": "UwVMWViRUsxf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFnS0lfBUsxf"
      },
      "source": [
        "## Non-degenerate Gaussian Processes\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/non-degenerate-gps.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/non-degenerate-gps.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "The process described above is degenerate. The covariance function is of\n",
        "rank at most $h$ and since the theoretical amount of data could always\n",
        "increase $n\\rightarrow \\infty$, the covariance function is not full\n",
        "rank. This means as we increase the amount of data to infinity, there\n",
        "will come a point where we can’t normalize the process because the\n",
        "multivariate Gaussian has the form, $$\n",
        "\\mathcal{N}\\left(\\mathbf{ f}|\\mathbf{0},\\mathbf{K}\\right) = \\frac{1}{\\left(2\\pi\\right)^{\\frac{n}{2}}\\det{\\mathbf{K}}^\\frac{1}{2}} \\exp\\left(-\\frac{\\mathbf{ f}^\\top\\mathbf{K}\\mathbf{ f}}{2}\\right)\n",
        "$$ and a non-degenerate kernel matrix leads to $\\det{\\mathbf{K}} = 0$\n",
        "defeating the normalization (it’s equivalent to finding a projection in\n",
        "the high dimensional Gaussian where the variance of the the resulting\n",
        "univariate Gaussian is zero, i.e. there is a null space on the\n",
        "covariance, or alternatively you can imagine there are one or more\n",
        "directions where the Gaussian has become the delta function).\n",
        "\n",
        "\\\\radfordNealPicture{15%} In the machine learning field, it was Radford\n",
        "Neal (Neal, 1994) that realized the potential of the next step. In his\n",
        "1994 thesis, he was considering Bayesian neural networks, of the type we\n",
        "described above, and in considered what would happen if you took the\n",
        "number of hidden nodes, or neurons, to infinity,\n",
        "i.e. $h\\rightarrow \\infty$.\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//neal-infinite-priors.png\" style=\"width:80%\">\n",
        "\n",
        "Figure: <i>Page 37 of [Radford Neal’s 1994\n",
        "thesis](http://www.cs.toronto.edu/~radford/ftp/thesis.pdf)</i>\n",
        "\n",
        "In loose terms, what Radford considers is what happens to the elements\n",
        "of the covariance function, $$\n",
        "  \\begin{align*}\n",
        "  k_f\\left(\\mathbf{ x}_i, \\mathbf{ x}_j\\right) & = \\alpha \\boldsymbol{ \\phi}\\left(\\mathbf{W}_1, \\mathbf{ x}_i\\right)^\\top \\boldsymbol{ \\phi}\\left(\\mathbf{W}_1, \\mathbf{ x}_j\\right)\\\\\n",
        "  & = \\alpha \\sum_k \\phi\\left(\\mathbf{ w}^{(1)}_k, \\mathbf{ x}_i\\right) \\phi\\left(\\mathbf{ w}^{(1)}_k, \\mathbf{ x}_j\\right)\n",
        "  \\end{align*}\n",
        "  $$ if instead of considering a finite number you sample infinitely\n",
        "many of these activation functions, sampling parameters from a prior\n",
        "density, $p(\\mathbf{ v})$, for each one, $$\n",
        "k_f\\left(\\mathbf{ x}_i, \\mathbf{ x}_j\\right) = \\alpha \\int \\phi\\left(\\mathbf{ w}^{(1)}, \\mathbf{ x}_i\\right) \\phi\\left(\\mathbf{ w}^{(1)}, \\mathbf{ x}_j\\right) p(\\mathbf{ w}^{(1)}) \\text{d}\\mathbf{ w}^{(1)}\n",
        "$$ And that’s not *only* for Gaussian $p(\\mathbf{ v})$. In fact this\n",
        "result holds for a range of activations, and a range of prior densities\n",
        "because of the *central limit theorem*.\n",
        "\n",
        "To write it in the form of a probabilistic program, as long as the\n",
        "distribution for $\\phi_i$ implied by this short probabilistic program,\n",
        "$$\n",
        "  \\begin{align*}\n",
        "  \\mathbf{ v}& \\sim p(\\cdot)\\\\\n",
        "  \\phi_i & = \\phi\\left(\\mathbf{ v}, \\mathbf{ x}_i\\right),\n",
        "  \\end{align*}\n",
        "  $$ has finite variance, then the result of taking the number of hidden\n",
        "units to infinity, with appropriate scaling, is also a Gaussian process."
      ],
      "id": "XFnS0lfBUsxf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTRk38BtUsxf"
      },
      "source": [
        "## Further Reading\n",
        "\n",
        "To understand this argument in more detail, I highly recommend reading\n",
        "chapter 2 of Neal’s thesis (Neal, 1994), which remains easy to read and\n",
        "clear today. Indeed, for readers interested in Bayesian neural networks,\n",
        "both Raford Neal’s and David MacKay’s PhD thesis (MacKay, 1992) remain\n",
        "essential reading. Both theses embody a clarity of thought, and an\n",
        "ability to weave together threads from different fields that was the\n",
        "business of machine learning in the 1990s. Radford and David were also\n",
        "pioneers in making their software widely available and publishing\n",
        "material on the web."
      ],
      "id": "sTRk38BtUsxf"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCvL1ftZUsxg"
      },
      "source": [
        "## Gaussian Process\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-function-space.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-function-space.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "In our we sampled from the prior over paraemters. Through the properties\n",
        "of multivariate Gaussian densities this prior over parameters implies a\n",
        "particular density for our data observations, $\\mathbf{ y}$. In this\n",
        "session we sampled directly from this distribution for our data,\n",
        "avoiding the intermediate weight-space representation. This is the\n",
        "approach taken by *Gaussian processes*. In a Gaussian process you\n",
        "specify the *covariance function* directly, rather than *implicitly*\n",
        "through a basis matrix and a prior over parameters. Gaussian processes\n",
        "have the advantage that they can be *nonparametric*, which in simple\n",
        "terms means that they can have *infinite* basis functions. In the\n",
        "lectures we introduced the *exponentiated quadratic* covariance, also\n",
        "known as the RBF or the Gaussian or the squared exponential covariance\n",
        "function. This covariance function is specified by $$\n",
        "k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\exp\\left( -\\frac{\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime\\right\\Vert^2}{2\\ell^2}\\right),\n",
        "$$ where $\\left\\Vert\\mathbf{ x}- \\mathbf{ x}^\\prime\\right\\Vert^2$ is the\n",
        "squared distance between the two input vectors $$\n",
        "\\left\\Vert\\mathbf{ x}- \\mathbf{ x}^\\prime\\right\\Vert^2 = (\\mathbf{ x}- \\mathbf{ x}^\\prime)^\\top (\\mathbf{ x}- \\mathbf{ x}^\\prime)\n",
        "$$ Let’s build a covariance matrix based on this function. First we\n",
        "define the form of the covariance function,"
      ],
      "id": "BCvL1ftZUsxg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbZIi9wLUsxg"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "zbZIi9wLUsxg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKHxsr68Usxg"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.eq_cov"
      ],
      "id": "SKHxsr68Usxg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRUXznkOUsxg"
      },
      "source": [
        "We can use this to compute *directly* the covariance for $\\mathbf{ f}$\n",
        "at the points given by `x_pred`. Let’s define a new function `K()` which\n",
        "does this,"
      ],
      "id": "vRUXznkOUsxg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7o_jKBr4Usxg"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "7o_jKBr4Usxg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHknZlejUsxh"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.Kernel"
      ],
      "id": "KHknZlejUsxh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9Or_f1NUsxh"
      },
      "source": [
        "Now we can image the resulting covariance,"
      ],
      "id": "X9Or_f1NUsxh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCDgSuEzUsxh"
      },
      "outputs": [],
      "source": [
        "kernel = Kernel(function=eq_cov, variance=1., lengthscale=10.)\n",
        "K = kernel.K(x_pred, x_pred)"
      ],
      "id": "iCDgSuEzUsxh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EchkF25lUsxh"
      },
      "source": [
        "To visualise the covariance between the points we can use the `imshow`\n",
        "function in matplotlib."
      ],
      "id": "EchkF25lUsxh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hK3I3QpFUsxh"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8,8))\n",
        "im = ax.imshow(K, interpolation='none')\n",
        "fig.colorbar(im)"
      ],
      "id": "hK3I3QpFUsxh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N48sK3e5Usxi"
      },
      "source": [
        "Finally, we can sample functions from the marginal likelihood."
      ],
      "id": "N48sK3e5Usxi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wukWLDC2Usxi"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "for i in range(10):\n",
        "    y_sample = np.random.multivariate_normal(mean=np.zeros(x_pred.size), cov=K)\n",
        "    ax.plot(x_pred.flatten(), y_sample.flatten())"
      ],
      "id": "wukWLDC2Usxi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc5NvPrhUsxi"
      },
      "source": [
        "### Exercise 1\n",
        "\n",
        "**Moving Parameters** Have a play with the parameters for this\n",
        "covariance function (the lengthscale and the variance) and see what\n",
        "effects the parameters have on the types of functions you observe."
      ],
      "id": "Gc5NvPrhUsxi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-dtiGrxUsxi"
      },
      "source": [
        "### Exercise 1 Answer\n",
        "\n",
        "Write your answer to Exercise 1 here"
      ],
      "id": "q-dtiGrxUsxi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQ94TsdhUsxi"
      },
      "outputs": [],
      "source": [
        "# Use this box for any code you need\n",
        "\n"
      ],
      "id": "jQ94TsdhUsxi"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cM4y64iUsxi"
      },
      "source": [
        "## Bayesian Inference by Rejection Sampling\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-intro-very-short.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-intro-very-short.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "One view of Bayesian inference is to assume we are given a mechanism for\n",
        "generating samples, where we assume that mechanism is representing an\n",
        "accurate view on the way we believe the world works.\n",
        "\n",
        "This mechanism is known as our *prior* belief.\n",
        "\n",
        "We combine our prior belief with our observations of the real world by\n",
        "discarding all those prior samples that are inconsistent with our\n",
        "observations. The *likelihood* defines mathematically what we mean by\n",
        "inconsistent with the observations. The higher the noise level in the\n",
        "likelihood, the looser the notion of consistent.\n",
        "\n",
        "The samples that remain are samples from the *posterior*.\n",
        "\n",
        "This approach to Bayesian inference is closely related to two sampling\n",
        "techniques known as *rejection sampling* and *importance sampling*. It\n",
        "is realized in practice in an approach known as *approximate Bayesian\n",
        "computation* (ABC) or likelihood-free inference.\n",
        "\n",
        "In practice, the algorithm is often too slow to be practical, because\n",
        "most samples will be inconsistent with the observations and as a result\n",
        "the mechanism must be operated many times to obtain a few posterior\n",
        "samples.\n",
        "\n",
        "However, in the Gaussian process case, when the likelihood also assumes\n",
        "Gaussian noise, we can operate this mechanism mathematically, and obtain\n",
        "the posterior density *analytically*. This is the benefit of Gaussian\n",
        "processes.\n",
        "\n",
        "First, we will load in two python functions for computing the covariance\n",
        "function."
      ],
      "id": "0cM4y64iUsxi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmGE5rXWUsxi"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "UmGE5rXWUsxi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwYOMZi4Usxj"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.Kernel"
      ],
      "id": "IwYOMZi4Usxj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9wcLIepJUsxj"
      },
      "outputs": [],
      "source": [
        "# %load -n mlai.Kernel\n",
        "class Kernel():\n",
        "    \"\"\"Covariance function\n",
        "    :param function: covariance function\n",
        "    :type function: function\n",
        "    :param name: name of covariance function\n",
        "    :type name: string\n",
        "    :param shortname: abbreviated name of covariance function\n",
        "    :type shortname: string\n",
        "    :param formula: latex formula of covariance function\n",
        "    :type formula: string\n",
        "    :param function: covariance function\n",
        "    :type function: function\n",
        "    :param \\**kwargs:\n",
        "        See below\n",
        "\n",
        "    :Keyword Arguments:\n",
        "        * \"\"\"\n",
        "\n",
        "    def __init__(self, function, name=None, shortname=None, formula=None, **kwargs):\n",
        "        self.function=function\n",
        "        self.formula = formula\n",
        "        self.name = name\n",
        "        self.shortname = shortname\n",
        "        self.parameters=kwargs\n",
        "\n",
        "    def K(self, X, X2=None):\n",
        "        \"\"\"Compute the full covariance function given a kernel function for two data points.\"\"\"\n",
        "        if X2 is None:\n",
        "            X2 = X\n",
        "        K = np.zeros((X.shape[0], X2.shape[0]))\n",
        "        for i in np.arange(X.shape[0]):\n",
        "            for j in np.arange(X2.shape[0]):\n",
        "                K[i, j] = self.function(X[i, :], X2[j, :], **self.parameters)\n",
        "\n",
        "        return K\n",
        "\n",
        "    def diag(self, X):\n",
        "        \"\"\"Compute the diagonal of the covariance function\"\"\"\n",
        "        diagK = np.zeros((X.shape[0], 1))\n",
        "        for i in range(X.shape[0]):\n",
        "            diagK[i] = self.function(X[i, :], X[i, :], **self.parameters)\n",
        "        return diagK\n",
        "\n",
        "    def _repr_html_(self):\n",
        "        raise NotImplementedError"
      ],
      "id": "9wcLIepJUsxj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1__9JTIUsxj"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "b1__9JTIUsxj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6jP1hZ8PUsxj"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.eq_cov"
      ],
      "id": "6jP1hZ8PUsxj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMIPXUy5Usxj"
      },
      "outputs": [],
      "source": [
        "# %load -n mlai.eq_cov\n",
        "def eq_cov(x, x_prime, variance=1., lengthscale=1.):\n",
        "    \"\"\"Exponentiated quadratic covariance function.\"\"\"\n",
        "    diffx = x - x_prime\n",
        "    return variance*np.exp(-0.5*np.dot(diffx, diffx)/lengthscale**2)"
      ],
      "id": "BMIPXUy5Usxj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6h82rmsdUsxk"
      },
      "outputs": [],
      "source": [
        "kernel = Kernel(function=eq_cov,\n",
        "                     name='Exponentiated Quadratic',\n",
        "                     shortname='eq',\n",
        "                     lengthscale=0.25)"
      ],
      "id": "6h82rmsdUsxk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFZgUhnlUsxk"
      },
      "source": [
        "Next, we sample from a multivariate normal density (a multivariate\n",
        "Gaussian), using the covariance function as the covariance matrix."
      ],
      "id": "GFZgUhnlUsxk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sL3y-OxrUsxk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(10)\n",
        "import mlai.plot as plot"
      ],
      "id": "sL3y-OxrUsxk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJc8IzIRUsxk"
      },
      "outputs": [],
      "source": [
        "plot.rejection_samples(kernel=kernel,\n",
        "    diagrams='./gp')"
      ],
      "id": "PJc8IzIRUsxk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP8qDFASUsxk"
      },
      "outputs": [],
      "source": [
        "import notutils as nu\n",
        "from ipywidgets import IntSlider"
      ],
      "id": "LP8qDFASUsxk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LduN5HWJUsxk"
      },
      "outputs": [],
      "source": [
        "nu.display_plots('gp_rejection_sample{sample:0>3}.png',\n",
        "                 directory='./gp',\n",
        "                 sample=IntSlider(1,1,5,1))"
      ],
      "id": "LduN5HWJUsxk"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpJAWjmcUsxl"
      },
      "source": [
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/gp_rejection_sample003.png\" style=\"width:100%\">\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/gp_rejection_sample004.png\" style=\"width:100%\">\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/gp_rejection_sample005.png\" style=\"width:100%\">\n",
        "\n",
        "Figure: <i>One view of Bayesian inference is we have a machine for\n",
        "generating samples (the *prior*), and we discard all samples\n",
        "inconsistent with our data, leaving the samples of interest (the\n",
        "*posterior*). This is a rejection sampling view of Bayesian inference.\n",
        "The Gaussian process allows us to do this analytically by multiplying\n",
        "the *prior* by the *likelihood*.</i>"
      ],
      "id": "ZpJAWjmcUsxl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTa3P3mTUsxl"
      },
      "source": [
        "## Gaussian Process\n",
        "\n",
        "The Gaussian process perspective takes the marginal likelihood of the\n",
        "data to be a joint Gaussian density with a covariance given by\n",
        "$\\mathbf{K}$. So the model likelihood is of the form, $$\n",
        "p(\\mathbf{ y}|\\mathbf{X}) =\n",
        "\\frac{1}{(2\\pi)^{\\frac{n}{2}}|\\mathbf{K}|^{\\frac{1}{2}}}\n",
        "\\exp\\left(-\\frac{1}{2}\\mathbf{ y}^\\top \\left(\\mathbf{K}+\\sigma^2\n",
        "\\mathbf{I}\\right)^{-1}\\mathbf{ y}\\right)\n",
        "$$ where the input data, $\\mathbf{X}$, influences the density through\n",
        "the covariance matrix, $\\mathbf{K}$ whose elements are computed through\n",
        "the covariance function, $k(\\mathbf{ x}, \\mathbf{ x}^\\prime)$.\n",
        "\n",
        "This means that the negative log likelihood (the objective function) is\n",
        "given by, $$\n",
        "E(\\boldsymbol{\\theta}) = \\frac{1}{2} \\log |\\mathbf{K}|\n",
        "+ \\frac{1}{2} \\mathbf{ y}^\\top \\left(\\mathbf{K}+\n",
        "\\sigma^2\\mathbf{I}\\right)^{-1}\\mathbf{ y}\n",
        "$$ where the *parameters* of the model are also embedded in the\n",
        "covariance function, they include the parameters of the kernel (such as\n",
        "lengthscale and variance), and the noise variance, $\\sigma^2$. Let’s\n",
        "create a set of classes in python for storing these variables."
      ],
      "id": "jTa3P3mTUsxl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZbKd5QGUsxl"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "nZbKd5QGUsxl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9Q9r0VKUsxl"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.Model"
      ],
      "id": "R9Q9r0VKUsxl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0qSrf1cUsxl"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "j0qSrf1cUsxl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7KHL7rKTUsxl"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.MapModel"
      ],
      "id": "7KHL7rKTUsxl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecscJs2BUsxl"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "ecscJs2BUsxl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_vRCIYJUsxm"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.ProbModel"
      ],
      "id": "X_vRCIYJUsxm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SBbXZ_2xUsxm"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "SBbXZ_2xUsxm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTWH7VRxUsxm"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.ProbMapModel"
      ],
      "id": "iTWH7VRxUsxm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxV0be0SUsxm"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "KxV0be0SUsxm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeE48i_RUsxm"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.GP"
      ],
      "id": "YeE48i_RUsxm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyOxuCsSUsxm"
      },
      "source": [
        "## Making Predictions\n",
        "\n",
        "We now have a probability density that represents functions. How do we\n",
        "make predictions with this density? The density is known as a process\n",
        "because it is *consistent*. By consistency, here, we mean that the model\n",
        "makes predictions for $\\mathbf{ f}$ that are unaffected by future values\n",
        "of $\\mathbf{ f}^*$ that are currently unobserved (such as test points).\n",
        "If we think of $\\mathbf{ f}^*$ as test points, we can still write down a\n",
        "joint probability density over the training observations, $\\mathbf{ f}$\n",
        "and the test observations, $\\mathbf{ f}^*$. This joint probability\n",
        "density will be Gaussian, with a covariance matrix given by our\n",
        "covariance function, $k(\\mathbf{ x}_i, \\mathbf{ x}_j)$. $$\n",
        "\\begin{bmatrix}\\mathbf{ f}\\\\ \\mathbf{ f}^*\\end{bmatrix} \\sim \\mathcal{N}\\left(\\mathbf{0},\\begin{bmatrix} \\mathbf{K}& \\mathbf{K}_\\ast \\\\\n",
        "\\mathbf{K}_\\ast^\\top & \\mathbf{K}_{\\ast,\\ast}\\end{bmatrix}\\right)\n",
        "$$ where here $\\mathbf{K}$ is the covariance computed between all the\n",
        "training points, $\\mathbf{K}_\\ast$ is the covariance matrix computed\n",
        "between the training points and the test points and\n",
        "$\\mathbf{K}_{\\ast,\\ast}$ is the covariance matrix computed betwen all\n",
        "the tests points and themselves. To be clear, let’s compute these now\n",
        "for our example, using `x` and `y` for the training data (although `y`\n",
        "doesn’t enter the covariance) and `x_pred` as the test locations."
      ],
      "id": "zyOxuCsSUsxm"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQqpqWlmUsxn"
      },
      "outputs": [],
      "source": [
        "# set covariance function parameters\n",
        "variance = 16.0\n",
        "lengthscale = 8\n",
        "# set noise variance\n",
        "sigma2 = 0.05\n",
        "\n",
        "kernel = Kernel(eq_cov, variance=variance, lengthscale=lengthscale)\n",
        "K = kernel.K(x, x)\n",
        "K_star = kernel.K(x, x_pred)\n",
        "K_starstar = kernel.K(x_pred, x_pred)"
      ],
      "id": "bQqpqWlmUsxn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OiHxfNtUsxn"
      },
      "source": [
        "Now we use this structure to visualise the covariance between test data\n",
        "and training data. This structure is how information is passed between\n",
        "test and training data. Unlike the maximum likelihood formalisms we’ve\n",
        "been considering so far, the structure expresses *correlation* between\n",
        "our different data points. However, just like the we now have a *joint\n",
        "density* between some variables of interest. In particular we have the\n",
        "joint density over $p(\\mathbf{ f}, \\mathbf{ f}^*)$. The joint density is\n",
        "*Gaussian* and *zero mean*. It is specified entirely by the *covariance\n",
        "matrix*, $\\mathbf{K}$. That covariance matrix is, in turn, defined by a\n",
        "covariance function. Now we will visualise the form of that covariance\n",
        "in the form of the matrix, $$\n",
        "\\begin{bmatrix} \\mathbf{K}& \\mathbf{K}_\\ast \\\\ \\mathbf{K}_\\ast^\\top\n",
        "& \\mathbf{K}_{\\ast,\\ast}\\end{bmatrix}\n",
        "$$"
      ],
      "id": "0OiHxfNtUsxn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Uzg37x2Usxn"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "8Uzg37x2Usxn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1w3g_grCUsxn"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=(8,8))\n",
        "im = ax.imshow(np.vstack([np.hstack([K, K_star]), np.hstack([K_star.T, K_starstar])]), interpolation='none')\n",
        "# Add lines for separating training and test data\n",
        "ax.axvline(x.shape[0]-1, color='w')\n",
        "ax.axhline(x.shape[0]-1, color='w')\n",
        "fig.colorbar(im)\n",
        "\n",
        "mlai.write_figure('block-predictive-covariance.svg', diagrams='./gp')"
      ],
      "id": "1w3g_grCUsxn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQRNBk8ZUsxn"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/block-predictive-covariance.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>Different blocks of the covariance function. The upper left\n",
        "block is the covariance of the training data with itself, $\\mathbf{K}$.\n",
        "The top right is the cross covariance between training data (rows) and\n",
        "prediction locations (columns). The lower left is the same matrix\n",
        "transposed. The bottom right is the covariance matrix of the test data\n",
        "with itself.</i>\n",
        "\n",
        "There are four blocks to this plot. The upper left block is the\n",
        "covariance of the training data with itself, $\\mathbf{K}$. We see some\n",
        "structure here due to the missing data from the first and second world\n",
        "wars. Alongside this covariance (to the right and below) we see the\n",
        "cross covariance between the training and the test data ($\\mathbf{K}_*$\n",
        "and $\\mathbf{K}_*^\\top$). This is giving us the covariation between our\n",
        "training and our test data. Finally the lower right block The banded\n",
        "structure we now observe is because some of the training points are near\n",
        "to some of the test points. This is how we obtain ‘communication’\n",
        "between our training data and our test data. If there is no structure in\n",
        "$\\mathbf{K}_*$ then our belief about the test data simply matches our\n",
        "prior."
      ],
      "id": "XQRNBk8ZUsxn"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQr485UUUsxn"
      },
      "source": [
        "## The Importance of the Covariance Function\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-covariance-function-importance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-covariance-function-importance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "The covariance function encapsulates our assumptions about the data. The\n",
        "equations for the distribution of the prediction function, given the\n",
        "training observations, are highly sensitive to the covariation between\n",
        "the test locations and the training locations as expressed by the matrix\n",
        "$\\mathbf{K}_*$. We defined a matrix $\\mathbf{A}$ which allowed us to\n",
        "express our conditional mean in the form, $$\n",
        "\\boldsymbol{ \\mu}_f= \\mathbf{A}^\\top \\mathbf{ y},\n",
        "$$ where $\\mathbf{ y}$ were our *training observations*. In other words\n",
        "our mean predictions are always a linear weighted combination of our\n",
        "*training data*. The weights are given by computing the covariation\n",
        "between the training and the test data ($\\mathbf{K}_*$) and scaling it\n",
        "by the inverse covariance of the training data observations,\n",
        "$\\left[\\mathbf{K}+ \\sigma^2 \\mathbf{I}\\right]^{-1}$. This inverse is the\n",
        "main computational object that needs to be resolved for a Gaussian\n",
        "process. It has a computational burden which is $O(n^3)$ and a storage\n",
        "burden which is $O(n^2)$. This makes working with Gaussian processes\n",
        "computationally intensive for the situation where $n>10,000$."
      ],
      "id": "RQr485UUUsxn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZMXdUooUsxo"
      },
      "outputs": [],
      "source": [
        "from IPython.lib.display import YouTubeVideo\n",
        "YouTubeVideo('ewJ3AxKclOg')"
      ],
      "id": "WZMXdUooUsxo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ml0cX-jUsxo"
      },
      "source": [
        "Figure: <i>Introduction to Gaussian processes given by Neil Lawrence at\n",
        "the 2014 Gaussian process Winter School at the University of\n",
        "Sheffield.</i>"
      ],
      "id": "1ml0cX-jUsxo"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEb3X_KkUsxo"
      },
      "source": [
        "## Improving the Numerics\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-numerics-and-optimization.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-numerics-and-optimization.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "In practice we shouldn’t be using matrix inverse directly to solve the\n",
        "GP system. One more stable way is to compute the *Cholesky\n",
        "decomposition* of the kernel matrix. The log determinant of the\n",
        "covariance can also be derived from the Cholesky decomposition."
      ],
      "id": "UEb3X_KkUsxo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQJrKj_4Usxo"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "hQJrKj_4Usxo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OhzYVWUUsxo"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.update_inverse"
      ],
      "id": "8OhzYVWUUsxo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dw4n5mJVUsxp"
      },
      "outputs": [],
      "source": [
        "GP.update_inverse = update_inverse"
      ],
      "id": "dw4n5mJVUsxp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXRj90MgUsxp"
      },
      "source": [
        "## Capacity Control\n",
        "\n",
        "Gaussian processes are sometimes seen as part of a wider family of\n",
        "methods known as kernel methods. Kernel methods are also based around\n",
        "covariance functions, but in the field they are known as Mercer kernels.\n",
        "Mercer kernels have interpretations as inner products in potentially\n",
        "infinite dimensional Hilbert spaces. This interpretation arises because,\n",
        "if we take $\\alpha=1$, then the kernel can be expressed as $$\n",
        "\\mathbf{K}= \\boldsymbol{ \\Phi}\\boldsymbol{ \\Phi}^\\top\n",
        "$$ which imples the elements of the kernel are given by, $$\n",
        "k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\boldsymbol{ \\phi}(\\mathbf{ x})^\\top \\boldsymbol{ \\phi}(\\mathbf{ x}^\\prime).\n",
        "$$ So we see that the kernel function is developed from an inner product\n",
        "between the basis functions. Mercer’s theorem tells us that any valid\n",
        "*positive definite function* can be expressed as this inner product but\n",
        "with the caveat that the inner product could be *infinite length*. This\n",
        "idea has been used quite widely to *kernelize* algorithms that depend on\n",
        "inner products. The kernel functions are equivalent to covariance\n",
        "functions and they are parameterized accordingly. In the kernel modeling\n",
        "community it is generally accepted that kernel parameter estimation is a\n",
        "difficult problem and the normal solution is to cross validate to obtain\n",
        "parameters. This can cause difficulties when a large number of kernel\n",
        "parameters need to be estimated. In Gaussian process modelling kernel\n",
        "parameter estimation (in the simplest case proceeds) by maximum\n",
        "likelihood. This involves taking gradients of the likelihood with\n",
        "respect to the parameters of the covariance function."
      ],
      "id": "KXRj90MgUsxp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5AgzN5BUsxp"
      },
      "source": [
        "## Gradients of the Likelihood\n",
        "\n",
        "The easiest conceptual way to obtain the gradients is a two step\n",
        "process. The first step involves taking the gradient of the likelihood\n",
        "with respect to the covariance function, the second step involves\n",
        "considering the gradient of the covariance function with respect to its\n",
        "parameters."
      ],
      "id": "h5AgzN5BUsxp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4REqYjDUsxp"
      },
      "source": [
        "## Overall Process Scale\n",
        "\n",
        "In general we won’t be able to find parameters of the covariance\n",
        "function through fixed point equations, we will need to do gradient\n",
        "based optimization."
      ],
      "id": "-4REqYjDUsxp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojsnQDoaUsxp"
      },
      "source": [
        "## Capacity Control and Data Fit\n",
        "\n",
        "The objective function can be decomposed into two terms, a capacity\n",
        "control term, and a data fit term. The capacity control term is the log\n",
        "determinant of the covariance. The data fit term is the matrix inner\n",
        "product between the data and the inverse covariance."
      ],
      "id": "ojsnQDoaUsxp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U9ZIoSsUsxp"
      },
      "outputs": [],
      "source": [
        "def rotateObject(rotationMatrix, handle):\n",
        "for i = 1:prod(size(handle))\n",
        "    type = get(handle(i), 'type');\n",
        "    if strcmp(type, 'text'):\n",
        "        xy = get(handle(i), 'position');\n",
        "        xy(1:2) = rotationMatrix*xy(1:2)';\n",
        "        set(handle(i), 'position', xy);\n",
        "    else:\n",
        "        xd = get(handle(i), 'xdata');\n",
        "        yd = get(handle(i), 'ydata');\n",
        "        new = rotationMatrix*[xd(:)'; yd(:)'];\n",
        "        set(handle(i), 'xdata', new(1, :));\n",
        "        set(handle(i), 'ydata', new(2, :));"
      ],
      "id": "8U9ZIoSsUsxp"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MF1ZUvtNUsxq"
      },
      "source": [
        "## Learning Covariance Parameters\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-optimize.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-optimize.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Can we determine covariance parameters from the data?\n",
        "\n",
        "$$\n",
        "\\mathcal{N}\\left(\\mathbf{ y}|\\mathbf{0},\\mathbf{K}\\right)=\\frac{1}{(2\\pi)^\\frac{n}{2}{\\det{\\mathbf{K}}^{\\frac{1}{2}}}}{\\exp\\left(-\\frac{\\mathbf{ y}^{\\top}\\mathbf{K}^{-1}\\mathbf{ y}}{2}\\right)}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "    \\mathcal{N}\\left(\\mathbf{ y}|\\mathbf{0},\\mathbf{K}\\right)=\\frac{1}{(2\\pi)^\\frac{n}{2}\\color{blue}{\\det{\\mathbf{K}}^{\\frac{1}{2}}}}\\color{red}{\\exp\\left(-\\frac{\\mathbf{ y}^{\\top}\\mathbf{K}^{-1}\\mathbf{ y}}{2}\\right)}\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{aligned}\n",
        "    \\log \\mathcal{N}\\left(\\mathbf{ y}|\\mathbf{0},\\mathbf{K}\\right)=&\\color{blue}{-\\frac{1}{2}\\log\\det{\\mathbf{K}}}\\color{red}{-\\frac{\\mathbf{ y}^{\\top}\\mathbf{K}^{-1}\\mathbf{ y}}{2}} \\\\ &-\\frac{n}{2}\\log2\\pi\n",
        "\\end{aligned}\n",
        "$$\n",
        "\n",
        "$$\n",
        "E(\\boldsymbol{ \\theta}) = \\color{blue}{\\frac{1}{2}\\log\\det{\\mathbf{K}}} + \\color{red}{\\frac{\\mathbf{ y}^{\\top}\\mathbf{K}^{-1}\\mathbf{ y}}{2}}\n",
        "$$"
      ],
      "id": "MF1ZUvtNUsxq"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_KhCQRIUsxq"
      },
      "source": [
        "## Capacity Control through the Determinant\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-optimize-capacity.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-optimize-capacity.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "The parameters are *inside* the covariance function (matrix).\n",
        "$$k_{i, j} = k(\\mathbf{ x}_i, \\mathbf{ x}_j; \\boldsymbol{ \\theta})$$\n",
        "\n",
        "$$\\mathbf{K}= \\mathbf{R}\\boldsymbol{ \\Lambda}^2 \\mathbf{R}^\\top$$\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<td width=\"50%\">\n",
        "\n",
        "<img class=\"negate\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/gp-optimize-eigen.png\" style=\"width:100%\">\n",
        "\n",
        "</td>\n",
        "<td width=\"50%\">\n",
        "\n",
        "$\\boldsymbol{ \\Lambda}$ represents distance on axes. $\\mathbf{R}$ gives\n",
        "rotation.\n",
        "\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "-   $\\boldsymbol{ \\Lambda}$ is *diagonal*,\n",
        "    $\\mathbf{R}^\\top\\mathbf{R}= \\mathbf{I}$.\n",
        "-   Useful representation since\n",
        "    $\\det{\\mathbf{K}} = \\det{\\boldsymbol{ \\Lambda}^2} = \\det{\\boldsymbol{ \\Lambda}}^2$."
      ],
      "id": "9_KhCQRIUsxq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7PQsxI-Usxq"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import mlai\n",
        "import mlai.plot as plot"
      ],
      "id": "V7PQsxI-Usxq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icnqpLD8Usxq"
      },
      "outputs": [],
      "source": [
        "plot.covariance_capacity(rotate_angle=np.pi/4, lambda1 = 0.5, lambda2 = 0.3, diagrams = './gp/')"
      ],
      "id": "icnqpLD8Usxq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZS7-vgjUsxq"
      },
      "outputs": [],
      "source": [
        "import notutils as nu\n",
        "from ipywidgets import IntSlider"
      ],
      "id": "_ZS7-vgjUsxq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMpm1OJzUsxr"
      },
      "outputs": [],
      "source": [
        "nu.display_plots('gp-optimise-determinant{sample:0>3}.svg',\n",
        "                                          directory='./gp',\n",
        "                              sample=IntSlider(0, 0, 9, 1))"
      ],
      "id": "gMpm1OJzUsxr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZyI2IGJUsxr"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/gp-optimise-determinant009.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>The determinant of the covariance is dependent only on the\n",
        "eigenvalues. It represents the ‘footprint’ of the Gaussian.</i>"
      ],
      "id": "KZyI2IGJUsxr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oYRgA4M0Usxr"
      },
      "source": [
        "## Quadratic Data Fit\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-optimize-data-fit.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-optimize-data-fit.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
      ],
      "id": "oYRgA4M0Usxr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QY4WIRsPUsxr"
      },
      "outputs": [],
      "source": [
        "    clf\n",
        "    includeText = [];\n",
        "    counter = 0;\n",
        "    plotWidth = 0.6*textWidth;\n",
        "    lambda1 = 3;\n",
        "    lambda2 = 1;\n",
        "    t = linspace(-pi, pi, 200);\n",
        "    R = [sqrt(2)/2 -sqrt(2)/2; sqrt(2)/2 sqrt(2)/2];\n",
        "    xy = [lambda1*sin(t); lambda2*cos(t)];\n",
        "    contourHand = line(xy(1, :), xy(2, :), 'color', blackColor);\n",
        "    xy = [lambda1*sin(t); lambda2*cos(t)]*2;\n",
        "    lim = [-1 1]*max([lambda1 lambda2])*2.2;\n",
        "    set(gca, 'xlim', lim, 'ylim', lim)\n",
        "    axis equal\n",
        "\n",
        "\n",
        "    contourHand = [contourHand line(xy(1, :), xy(2, :), 'color', blackColor)];\n",
        "    set(contourHand, 'linewidth', 2, 'color', redColor)\n",
        "    arrowHand = arrow([0 lambda1], [0 0]);\n",
        "    arrowHand = [arrowHand arrow([0 0], [0 lambda2])];\n",
        "    set(arrowHand, 'linewidth', 3, 'color', blackColor);\n",
        "    xlim = get(gca, 'xlim');\n",
        "    xspan = xlim(2) - xlim(1);\n",
        "    ylim = get(gca, 'ylim');\n",
        "    yspan = ylim(2) - ylim(1);\n",
        "    eigLabel = text(lambda1*0.5, -yspan*0.05, '$\\eigenvalue_1$', 'horizontalalignment', 'center');\n",
        "    eigLabel = [eigLabel text(-0.05*xspan, lambda2*0.5, '$\\eigenvalue_2$', 'horizontalalignment', 'center')];\n",
        "    xlabel('$\\dataScalar_1$')\n",
        "    ylabel('$\\dataScalar_2$')\n",
        "\n",
        "    box off\n",
        "    xlim = get(gca, 'xlim');\n",
        "    ylim = get(gca, 'ylim');\n",
        "    line([xlim(1) xlim(1)], ylim, 'color', blackColor)\n",
        "    line(xlim, [ylim(1) ylim(1)], 'color', blackColor)\n",
        "\n",
        "    fileName = ['gpOptimiseQuadratic' num2str(counter)];\n",
        "    printLatexPlot(fileName, directory, plotWidth);\n",
        "    includeText = [includeText '\\only<' num2str(counter) '>{\\input{' directory fileName '.svg}}'];\n",
        "    counter = counter + 1;\n",
        "\n",
        "    y = [1.2 1.4];\n",
        "    dataHand = line(y(1), y(2), 'marker', 'x', 'markersize', markerSize, 'linewidth', markerWidth, 'color', blackColor);\n",
        "\n",
        "    fileName = ['gpOptimiseQuadratic' num2str(counter)];\n",
        "    printLatexPlot(fileName, directory, plotWidth);\n",
        "    includeText = [includeText '\\only<' num2str(counter) '>{\\input{' directory fileName '.svg}}'];\n",
        "    counter = counter + 1;\n",
        "\n",
        "\n",
        "    rotateObject(rotationMatrix, arrowHand);\n",
        "    rotateObject(rotationMatrix, contourHand);\n",
        "    rotateObject(rotationMatrix, eigLabel);\n",
        "\n",
        "    fileName = ['gpOptimiseQuadratic' num2str(counter)];\n",
        "    printLatexPlot(fileName, directory, plotWidth);\n",
        "    includeText = [includeText '\\only<' num2str(counter) '>{\\input{' directory fileName '.svg}}'];\n",
        "    counter = counter + 1;\n",
        "\n",
        "    printLatexText(includeText, 'gpOptimiseQuadraticIncludeText.tex', directory)"
      ],
      "id": "QY4WIRsPUsxr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjfaqD0FUsxs"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/gp-optimise-quadratic002.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>The data fit term of the Gaussian process is a quadratic loss\n",
        "centered around zero. This has eliptical contours, the principal axes of\n",
        "which are given by the covariance matrix.</i>"
      ],
      "id": "kjfaqD0FUsxs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRt8OZ7AUsxs"
      },
      "source": [
        "## Data Fit Term\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-optimize-data-fit-capacity.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-optimize-data-fit-capacity.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
      ],
      "id": "gRt8OZ7AUsxs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7ZtU4XLUsxs"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os"
      ],
      "id": "g7ZtU4XLUsxs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K7vztRweUsxs"
      },
      "outputs": [],
      "source": [
        "import GPy\n",
        "import mlai.plot as plot\n",
        "import mlai\n",
        "import gp_tutorial"
      ],
      "id": "K7vztRweUsxs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rfFfrUJUsxs"
      },
      "outputs": [],
      "source": [
        "np.random.seed(125)\n",
        "diagrams = './gp'\n",
        "\n",
        "black_color=[0., 0., 0.]\n",
        "red_color=[1., 0., 0.]\n",
        "blue_color=[0., 0., 1.]\n",
        "magenta_color=[1., 0., 1.]\n",
        "fontsize=18"
      ],
      "id": "5rfFfrUJUsxs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN3a4CpxUsxs"
      },
      "outputs": [],
      "source": [
        "y_lim = [-2.2, 2.2]\n",
        "y_ticks = [-2, -1, 0, 1, 2]\n",
        "x_lim = [-2, 2]\n",
        "x_ticks = [-2, -1, 0, 1, 2]\n",
        "err_y_lim = [-12, 20]\n",
        "\n",
        "linewidth=3\n",
        "markersize=15\n",
        "markertype='.'"
      ],
      "id": "ZN3a4CpxUsxs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B_AKrLL7Usxt"
      },
      "outputs": [],
      "source": [
        "x = np.linspace(-1, 1, 6)[:, np.newaxis]\n",
        "xtest = np.linspace(x_lim[0], x_lim[1], 200)[:, np.newaxis]\n",
        "\n",
        "# True data\n",
        "true_kern = GPy.kern.RBF(1) + GPy.kern.White(1)\n",
        "true_kern.rbf.lengthscale = 1.0\n",
        "true_kern.white.variance = 0.01\n",
        "K = true_kern.K(x)\n",
        "y = np.random.multivariate_normal(np.zeros((6,)), K, 1).T"
      ],
      "id": "B_AKrLL7Usxt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDqq95TIUsxt"
      },
      "outputs": [],
      "source": [
        "# Fitted model\n",
        "kern = GPy.kern.RBF(1) + GPy.kern.White(1)\n",
        "kern.rbf.lengthscale = 1.0\n",
        "kern.white.variance = 0.01\n",
        "\n",
        "lengthscales = np.asarray([0.01, 0.05, 0.1, 0.25, 0.5, 1, 2, 4, 8, 16, 100])\n",
        "\n",
        "fig1, ax1 = plt.subplots(figsize=plot.one_figsize)\n",
        "fig2, ax2 = plt.subplots(figsize=plot.one_figsize)\n",
        "line = ax2.semilogx(np.NaN, np.NaN, 'x-',\n",
        "                    color=black_color)\n",
        "ax.set_ylim(err_y_lim)\n",
        "ax.set_xlim([0.025, 32])\n",
        "ax.grid(True)\n",
        "ax.set_xticks([0.01, 0.1, 1, 10, 100])\n",
        "ax.set_xticklabels(['$10^{-2}$', '$10^{-1}$', '$10^0$', '$10^1$', '$10^2$'])\n",
        "\n",
        "\n",
        "err = np.zeros_like(lengthscales)\n",
        "err_log_det = np.zeros_like(lengthscales)\n",
        "err_fit = np.zeros_like(lengthscales)\n",
        "\n",
        "counter = 0\n",
        "for i, ls in enumerate(lengthscales):\n",
        "        kern.rbf.lengthscale=ls\n",
        "        K = kern.K(x)\n",
        "        invK, L, Li, log_det_K = GPy.util.linalg.pdinv(K)\n",
        "        err[i] = 0.5*(log_det_K + np.dot(np.dot(y.T,invK),y))\n",
        "        err_log_det[i] = 0.5*log_det_K\n",
        "        err_fit[i] = 0.5*np.dot(np.dot(y.T,invK), y)\n",
        "        Kx = kern.K(x, xtest)\n",
        "        ypred_mean = np.dot(np.dot(Kx.T, invK), y)\n",
        "        ypred_var = kern.Kdiag(xtest) - np.sum((np.dot(Kx.T,invK))*Kx.T, 1)\n",
        "        ypred_sd = np.sqrt(ypred_var)\n",
        "        ax1.clear()\n",
        "        _ = gp_tutorial.gpplot(xtest.flatten(),\n",
        "                               ypred_mean.flatten(),\n",
        "                               ypred_mean.flatten()-2*ypred_sd.flatten(),\n",
        "                               ypred_mean.flatten()+2*ypred_sd.flatten(),\n",
        "                               ax=ax1)\n",
        "        x_lim = ax1.get_xlim()\n",
        "        ax1.set_ylabel('$f(x)$', fontsize=fontsize)\n",
        "        ax1.set_xlabel('$x$', fontsize=fontsize)\n",
        "\n",
        "        p = ax1.plot(x, y, markertype, color=black_color, markersize=markersize, linewidth=linewidth)\n",
        "        ax1.set_ylim(y_lim)\n",
        "        ax1.set_xlim(x_lim)\n",
        "        ax1.set_xticks(x_ticks)\n",
        "        #ax.set(box=False)\n",
        "\n",
        "        ax1.plot([x_lim[0], x_lim[0]], y_lim, color=black_color)\n",
        "        ax1.plot(x_lim, [y_lim[0], y_lim[0]], color=black_color)\n",
        "\n",
        "        file_name = 'gp-optimise{counter:0>3}.svg'.format(counter=counter)\n",
        "        mlai.write_figure(os.path.join(diagrams, file_name),\n",
        "                          figure=fig1,\n",
        "                          transparent=True)\n",
        "        counter += 1\n",
        "\n",
        "        ax2.clear()\n",
        "        t = ax2.semilogx(lengthscales[0:i+1], err[0:i+1], 'x-',\n",
        "                        color=magenta_color,\n",
        "                        markersize=markersize,\n",
        "                        linewidth=linewidth)\n",
        "        t2 = ax2.semilogx(lengthscales[0:i+1], err_log_det[0:i+1], 'x-',\n",
        "                         color=blue_color,\n",
        "                        markersize=markersize,\n",
        "                        linewidth=linewidth)\n",
        "        t3 = ax2.semilogx(lengthscales[0:i+1], err_fit[0:i+1], 'x-',\n",
        "                         color=red_color,\n",
        "                        markersize=markersize,\n",
        "                        linewidth=linewidth)\n",
        "        ax2.set_ylim(err_y_lim)\n",
        "        ax2.set_xlim([0.025, 32])\n",
        "        ax2.set_xticks([0.01, 0.1, 1, 10, 100])\n",
        "        ax2.set_xticklabels(['$10^{-2}$', '$10^{-1}$', '$10^0$', '$10^1$', '$10^2$'])\n",
        "\n",
        "        ax2.grid(True)\n",
        "\n",
        "        ax2.set_ylabel('negative log likelihood', fontsize=fontsize)\n",
        "        ax2.set_xlabel('length scale, $\\ell$', fontsize=fontsize)\n",
        "        file_name = 'gp-optimise{counter:0>3}.svg'.format(counter=counter)\n",
        "        mlai.write_figure(os.path.join(diagrams, file_name),\n",
        "                          figure=fig2,\n",
        "                          transparent=True)\n",
        "        counter += 1\n",
        "        #ax.set_box(False)\n",
        "        xlim = ax2.get_xlim()\n",
        "        ax2.plot([xlim[0], xlim[0]], err_y_lim, color=black_color)\n",
        "        ax2.plot(xlim, [err_y_lim[0], err_y_lim[0]], color=black_color)"
      ],
      "id": "mDqq95TIUsxt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj5CEltzUsxt"
      },
      "source": [
        "<table>\n",
        "<tr>\n",
        "<td width=\"50%\">\n",
        "\n",
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/gp-optimise006.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "</td>\n",
        "<td width=\"50%\">\n",
        "\n",
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/gp-optimise010.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n",
        "<table>\n",
        "<tr>\n",
        "<td width=\"50%\">\n",
        "\n",
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/gp-optimise016.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "</td>\n",
        "<td width=\"50%\">\n",
        "\n",
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/gp-optimise021.svg\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "Figure: <i>Variation in the data fit term, the capacity term and the\n",
        "negative log likelihood for different lengthscales.</i>"
      ],
      "id": "Pj5CEltzUsxt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzlxHbHBUsxt"
      },
      "source": [
        "## Exponentiated Quadratic Covariance\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_kern/includes/eq-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/eq-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
      ],
      "id": "CzlxHbHBUsxt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orVx5siRUsxt"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "orVx5siRUsxt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f7v7H_lJUsxu"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.Kernel"
      ],
      "id": "f7v7H_lJUsxu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehDnROmaUsxu"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "ehDnROmaUsxu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ATCA5qrBUsxu"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.eq_cov"
      ],
      "id": "ATCA5qrBUsxu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ_bJbUhUsxu"
      },
      "outputs": [],
      "source": [
        "kernel = Kernel(function=eq_cov,\n",
        "                     name='Exponentiated Quadratic',\n",
        "                     shortname='eq',\n",
        "                     formula='\\kernelScalar(\\inputVector, \\inputVector^\\prime) = \\alpha \\exp\\left(-\\frac{\\ltwoNorm{\\inputVector-\\inputVector^\\prime}^2}{2\\lengthScale^2}\\right)',\n",
        "                     lengthscale=0.2)"
      ],
      "id": "eZ_bJbUhUsxu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKwCmaqKUsxu"
      },
      "outputs": [],
      "source": [
        "import mlai.plot as plot"
      ],
      "id": "vKwCmaqKUsxu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6MqkJ1mNUsxu"
      },
      "outputs": [],
      "source": [
        "plot.covariance_func(kernel=kernel, diagrams='./kern/')"
      ],
      "id": "6MqkJ1mNUsxu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pehmaQ9dUsxv"
      },
      "source": [
        "The exponentiated quadratic covariance, also known as the Gaussian\n",
        "covariance or the RBF covariance and the squared exponential. Covariance\n",
        "between two points is related to the negative exponential of the squared\n",
        "distnace between those points. This covariance function can be derived\n",
        "in a few different ways: as the infinite limit of a radial basis\n",
        "function neural network, as diffusion in the heat equation, as a\n",
        "Gaussian filter in *Fourier space* or as the composition as a series of\n",
        "linear filters applied to a base function.\n",
        "\n",
        "The covariance takes the following form, $$\n",
        "k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\exp\\left(-\\frac{\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2^2}{2\\ell^2}\\right)\n",
        "$$ where $\\ell$ is the *length scale* or *time scale* of the process and\n",
        "$\\alpha$ represents the overall process variance.\n",
        "\n",
        "<center>\n",
        "\n",
        "$$k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\exp\\left(-\\frac{\\left\\Vert \\mathbf{ x}-\\mathbf{ x}^\\prime \\right\\Vert_2^2}{2\\ell^2}\\right)$$\n",
        "\n",
        "</center>\n",
        "<table>\n",
        "<tr>\n",
        "<td width=\"45%\">\n",
        "\n",
        "<img src=\"https://github.com/mlatcl/mlfc/blob/gh-pages/slides/diagrams/kern/eq_covariance.svg?raw=1\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "</td>\n",
        "<td width=\"45%\">\n",
        "\n",
        "<img class=\"negate\" src=\"https://github.com/mlatcl/mlfc/blob/gh-pages/slides/diagrams/kern/eq_covariance.gif?raw=1\" style=\"width:100%\">\n",
        "\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "Figure: <i>The exponentiated quadratic covariance function.</i>"
      ],
      "id": "pehmaQ9dUsxv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXVGiThvUsxv"
      },
      "source": [
        "## Olympic Marathon Data\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_datasets/includes/olympic-marathon-data.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/olympic-marathon-data.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<td width=\"70%\">\n",
        "\n",
        "-   Gold medal times for Olympic Marathon since 1896.\n",
        "-   Marathons before 1924 didn’t have a standardized distance.\n",
        "-   Present results using pace per km.\n",
        "-   In 1904 Marathon was badly organized leading to very slow times.\n",
        "\n",
        "</td>\n",
        "<td width=\"30%\">\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//datasets/eliud-kipchoge_berlin_2015.jpg\" style=\"width:100%\">\n",
        "<small>Image from [Wikimedia\n",
        "Commons](https://commons.wikimedia.org/wiki/File:Eliud_Kipchoge_in_Berlin_-_2015_(cropped).jpg)</small>\n",
        "\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "The first thing we will do is load a standard data set for regression\n",
        "modelling. The data consists of the pace of Olympic Gold Medal Marathon\n",
        "winners for the Olympics from 1896 to present. Let’s load in the data\n",
        "and plot."
      ],
      "id": "IXVGiThvUsxv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O_xt5Dj5Usxv"
      },
      "outputs": [],
      "source": [
        "%pip install pods"
      ],
      "id": "O_xt5Dj5Usxv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5saSLNoWUsxv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pods"
      ],
      "id": "5saSLNoWUsxv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUWfAQEFUsxv"
      },
      "outputs": [],
      "source": [
        "data = pods.datasets.olympic_marathon_men()\n",
        "x = data['X']\n",
        "y = data['Y']\n",
        "\n",
        "offset = y.mean()\n",
        "scale = np.sqrt(y.var())\n",
        "yhat = (y - offset)/scale"
      ],
      "id": "QUWfAQEFUsxv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZsZUiXfUsxw"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import mlai.plot as plot\n",
        "import mlai"
      ],
      "id": "1ZsZUiXfUsxw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pRtr8IoUsxw"
      },
      "outputs": [],
      "source": [
        "xlim = (1875,2030)\n",
        "ylim = (2.5, 6.5)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
        "_ = ax.plot(x, y, 'r.',markersize=10)\n",
        "ax.set_xlabel('year', fontsize=20)\n",
        "ax.set_ylabel('pace min/km', fontsize=20)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)\n",
        "\n",
        "mlai.write_figure(filename='olympic-marathon.svg',\n",
        "                  directory='./datasets')"
      ],
      "id": "9pRtr8IoUsxw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvJKa7DxUsxw"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//datasets/olympic-marathon.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>Olympic marathon pace times since 1896.</i>\n",
        "\n",
        "Things to notice about the data include the outlier in 1904, in that\n",
        "year the Olympics was in St Louis, USA. Organizational problems and\n",
        "challenges with dust kicked up by the cars following the race meant that\n",
        "participants got lost, and only very few participants completed. More\n",
        "recent years see more consistently quick marathons."
      ],
      "id": "hvJKa7DxUsxw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLqLVWfuUsxw"
      },
      "source": [
        "## Alan Turing\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_ml/includes/alan-turing-marathon.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_ml/includes/alan-turing-marathon.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<td width=\"50%\">\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//turing-times.gif\" style=\"width:100%\">\n",
        "\n",
        "</td>\n",
        "<td width=\"50%\">\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//turing-run.jpg\" style=\"width:50%\">\n",
        "\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "Figure: <i>Alan Turing, in 1946 he was only 11 minutes slower than the\n",
        "winner of the 1948 games. Would he have won a hypothetical games held in\n",
        "1946? Source:\n",
        "<a href=\"http://www.turing.org.uk/scrapbook/run.html\" target=\"_blank\">Alan\n",
        "Turing Internet Scrapbook</a>.</i>\n",
        "\n",
        "If we had to summarise the objectives of machine learning in one word, a\n",
        "very good candidate for that word would be *generalization*. What is\n",
        "generalization? From a human perspective it might be summarised as the\n",
        "ability to take lessons learned in one domain and apply them to another\n",
        "domain. If we accept the definition given in the first session for\n",
        "machine learning, $$\n",
        "\\text{data} + \\text{model} \\stackrel{\\text{compute}}{\\rightarrow} \\text{prediction}\n",
        "$$ then we see that without a model we can’t generalise: we only have\n",
        "data. Data is fine for answering very specific questions, like “Who won\n",
        "the Olympic Marathon in 2012?” because we have that answer stored,\n",
        "however, we are not given the answer to many other questions. For\n",
        "example, Alan Turing was a formidable marathon runner, in 1946 he ran a\n",
        "time 2 hours 46 minutes (just under four minutes per kilometer, faster\n",
        "than I and most of the other [Endcliffe Park\n",
        "Run](http://www.parkrun.org.uk/sheffieldhallam/) runners can do 5 km).\n",
        "What is the probability he would have won an Olympics if one had been\n",
        "held in 1946?\n",
        "\n",
        "To answer this question we need to generalize, but before we formalize\n",
        "the concept of generalization let’s introduce some formal representation\n",
        "of what it means to generalize in machine learning."
      ],
      "id": "xLqLVWfuUsxw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnmGb0-DUsxx"
      },
      "source": [
        "## Gaussian Process Fit\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/olympic-marathon-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/olympic-marathon-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Our first objective will be to perform a Gaussian process fit to the\n",
        "data, we’ll do this using the [GPy\n",
        "software](https://github.com/SheffieldML/GPy)."
      ],
      "id": "DnmGb0-DUsxx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcYyfUZ7Usxx"
      },
      "outputs": [],
      "source": [
        "import GPy"
      ],
      "id": "VcYyfUZ7Usxx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn3onUYNUsxx"
      },
      "outputs": [],
      "source": [
        "m_full = GPy.models.GPRegression(x,yhat)\n",
        "_ = m_full.optimize() # Optimize parameters of covariance function"
      ],
      "id": "zn3onUYNUsxx"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zo6Eza-cUsxx"
      },
      "source": [
        "The first command sets up the model, then `m_full.optimize()` optimizes\n",
        "the parameters of the covariance function and the noise level of the\n",
        "model. Once the fit is complete, we’ll try creating some test points,\n",
        "and computing the output of the GP model in terms of the mean and\n",
        "standard deviation of the posterior functions between 1870 and 2030. We\n",
        "plot the mean function and the standard deviation at 200 locations. We\n",
        "can obtain the predictions using `y_mean, y_var = m_full.predict(xt)`"
      ],
      "id": "zo6Eza-cUsxx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5i_vVuwUsxy"
      },
      "outputs": [],
      "source": [
        "xt = np.linspace(1870,2030,200)[:,np.newaxis]\n",
        "yt_mean, yt_var = m_full.predict(xt)\n",
        "yt_sd=np.sqrt(yt_var)"
      ],
      "id": "V5i_vVuwUsxy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Duvn4McGUsxy"
      },
      "source": [
        "Now we plot the results using the helper function in `mlai.plot`."
      ],
      "id": "Duvn4McGUsxy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TnEQqmNlUsxy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import mlai.plot as plot\n",
        "import mlai"
      ],
      "id": "TnEQqmNlUsxy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ep6nLThpUsxy"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
        "plot.model_output(m_full, scale=scale, offset=offset, ax=ax, xlabel=\"year\", ylabel=\"pace min/km\", fontsize=20, portion=0.2)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)\n",
        "mlai.write_figure(figure=fig,\n",
        "                  filename=\"olympic-marathon-gp.svg\",\n",
        "                  directory = \"./gp\",\n",
        "                  transparent=True, frameon=True)"
      ],
      "id": "Ep6nLThpUsxy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C3DiiRsbUsxz"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/olympic-marathon-gp.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>Gaussian process fit to the Olympic Marathon data. The error\n",
        "bars are too large, perhaps due to the outlier from 1904.</i>"
      ],
      "id": "C3DiiRsbUsxz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qht1FHPfUsxz"
      },
      "source": [
        "## Fit Quality\n",
        "\n",
        "In the fit we see that the error bars (coming mainly from the noise\n",
        "variance) are quite large. This is likely due to the outlier point in\n",
        "1904, ignoring that point we can see that a tighter fit is obtained. To\n",
        "see this make a version of the model, `m_clean`, where that point is\n",
        "removed."
      ],
      "id": "qht1FHPfUsxz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t0oKXWAUsxz"
      },
      "outputs": [],
      "source": [
        "x_clean=np.vstack((x[0:2, :], x[3:, :]))\n",
        "y_clean=np.vstack((yhat[0:2, :], yhat[3:, :]))\n",
        "\n",
        "m_clean = GPy.models.GPRegression(x_clean,y_clean)\n",
        "_ = m_clean.optimize()"
      ],
      "id": "2t0oKXWAUsxz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIf4smaBUsxz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import mlai.plot as plot\n",
        "import mlai"
      ],
      "id": "jIf4smaBUsxz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hj9buIPmUsxz"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
        "plot.model_output(m_clean, scale=scale, offset=offset, ax=ax, xlabel='year', ylabel='pace min/km', fontsize=20, portion=0.2)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)\n",
        "mlai.write_figure(figure=fig,\n",
        "                  filename='./gp/olympic-marathon-gp.svg',\n",
        "                  transparent=True, frameon=True)"
      ],
      "id": "Hj9buIPmUsxz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frb3LatPUsxz"
      },
      "source": [
        "## Gene Expression Example\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/della-gatta-gene-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/della-gatta-gene-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "We now consider an example in gene expression. Gene expression is the\n",
        "measurement of mRNA levels expressed in cells. These mRNA levels show\n",
        "which genes are ‘switched on’ and producing data. In the example we will\n",
        "use a Gaussian process to determine whether a given gene is active, or\n",
        "we are merely observing a noise response."
      ],
      "id": "frb3LatPUsxz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Z7sZeebUsxz"
      },
      "source": [
        "## Della Gatta Gene Data\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_datasets/includes/della-gatta-gene-data.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_datasets/includes/della-gatta-gene-data.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "-   Given given expression levels in the form of a time series from\n",
        "    Della Gatta et al. (2008)."
      ],
      "id": "_Z7sZeebUsxz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxV3oYcSUsx0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pods"
      ],
      "id": "dxV3oYcSUsx0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3a0-kQK0Usx0"
      },
      "outputs": [],
      "source": [
        "data = pods.datasets.della_gatta_TRP63_gene_expression(data_set='della_gatta',gene_number=937)\n",
        "\n",
        "x = data['X']\n",
        "y = data['Y']\n",
        "\n",
        "offset = y.mean()\n",
        "scale = np.sqrt(y.var())"
      ],
      "id": "3a0-kQK0Usx0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmLQG_M1Usx0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import mlai.plot as plot\n",
        "import mlai"
      ],
      "id": "cmLQG_M1Usx0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqnnoU6TUsx0"
      },
      "outputs": [],
      "source": [
        "xlim = (-20,260)\n",
        "ylim = (5, 7.5)\n",
        "yhat = (y-offset)/scale\n",
        "\n",
        "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
        "_ = ax.plot(x, y, 'r.',markersize=10)\n",
        "ax.set_xlabel('time/min', fontsize=20)\n",
        "ax.set_ylabel('expression', fontsize=20)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)\n",
        "\n",
        "mlai.write_figure(figure=fig,\n",
        "                  filename='./datasets/della-gatta-gene.svg',\n",
        "                  transparent=True,\n",
        "                  frameon=True)"
      ],
      "id": "xqnnoU6TUsx0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRndzPtCUsx0"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//datasets/della-gatta-gene.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>Gene expression levels over time for a gene from data\n",
        "provided by Della Gatta et al. (2008). We would like to understand\n",
        "whether there is signal in the data, or we are only observing noise.</i>\n",
        "\n",
        "-   Want to detect if a gene is expressed or not, fit a GP to each gene\n",
        "    Kalaitzis and Lawrence (2011).\n",
        "\n",
        "\\\\freddieKalaitzisPicture{15%}\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//health/1471-2105-12-180_1.png\" style=\"width:80%\">\n",
        "\n",
        "Figure: <i>The example is taken from the paper “A Simple Approach to\n",
        "Ranking Differentially Expressed Gene Expression Time Courses through\n",
        "Gaussian Process Regression.” Kalaitzis and Lawrence (2011).</i>\n",
        "\n",
        "<center>\n",
        "\n",
        "<http://www.biomedcentral.com/1471-2105/12/180>\n",
        "\n",
        "</center>\n",
        "\n",
        "Our first objective will be to perform a Gaussian process fit to the\n",
        "data, we’ll do this using the [GPy\n",
        "software](https://github.com/SheffieldML/GPy)."
      ],
      "id": "vRndzPtCUsx0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t66_u-WOUsx0"
      },
      "outputs": [],
      "source": [
        "import GPy"
      ],
      "id": "t66_u-WOUsx0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9stUIFjxUsx0"
      },
      "outputs": [],
      "source": [
        "m_full = GPy.models.GPRegression(x,yhat)\n",
        "m_full.kern.lengthscale=50\n",
        "_ = m_full.optimize() # Optimize parameters of covariance function"
      ],
      "id": "9stUIFjxUsx0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JM-W2SJgUsx1"
      },
      "source": [
        "Initialize the length scale parameter (which here actually represents a\n",
        "*time scale* of the covariance function) to a reasonable value. Default\n",
        "would be 1, but here we set it to 50 minutes, given points are arriving\n",
        "across zero to 250 minutes."
      ],
      "id": "JM-W2SJgUsx1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YUnEhoGdUsx1"
      },
      "outputs": [],
      "source": [
        "xt = np.linspace(-20,260,200)[:,np.newaxis]\n",
        "yt_mean, yt_var = m_full.predict(xt)\n",
        "yt_sd=np.sqrt(yt_var)"
      ],
      "id": "YUnEhoGdUsx1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuKrSP-mUsx1"
      },
      "source": [
        "Now we plot the results using the helper function in `mlai.plot`."
      ],
      "id": "XuKrSP-mUsx1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7fF6H79Usx1"
      },
      "outputs": [],
      "source": [
        "import mlai.plot as plot"
      ],
      "id": "s7fF6H79Usx1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56YfEXC9Usx1"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
        "plot.model_output(m_full, scale=scale, offset=offset, ax=ax, xlabel='time/min', ylabel='expression', fontsize=20, portion=0.2)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)\n",
        "ax.set_title('log likelihood: {ll:.3}'.format(ll=m_full.log_likelihood()), fontsize=20)\n",
        "mlai.write_figure(figure=fig,\n",
        "                  filename='./gp/della-gatta-gene-gp.svg',\n",
        "                  transparent=True, frameon=True)"
      ],
      "id": "56YfEXC9Usx1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LROWJHN_Usx1"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/della-gatta-gene-gp.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>Result of the fit of the Gaussian process model with the time\n",
        "scale parameter initialized to 50 minutes.</i>\n",
        "\n",
        "Now we try a model initialized with a longer length scale."
      ],
      "id": "LROWJHN_Usx1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTKQIpMqUsx2"
      },
      "outputs": [],
      "source": [
        "m_full2 = GPy.models.GPRegression(x,yhat)\n",
        "m_full2.kern.lengthscale=2000\n",
        "_ = m_full2.optimize() # Optimize parameters of covariance function"
      ],
      "id": "uTKQIpMqUsx2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Al_pLmxnUsx2"
      },
      "outputs": [],
      "source": [
        "import mlai.plot as plot"
      ],
      "id": "Al_pLmxnUsx2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G63CcmAPUsx2"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
        "plot.model_output(m_full2, scale=scale, offset=offset, ax=ax, xlabel='time/min', ylabel='expression', fontsize=20, portion=0.2)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)\n",
        "ax.set_title('log likelihood: {ll:.3}'.format(ll=m_full2.log_likelihood()), fontsize=20)\n",
        "mlai.write_figure(figure=fig,\n",
        "                  filename='./gp/della-gatta-gene-gp2.svg',\n",
        "                  transparent=True, frameon=True)"
      ],
      "id": "G63CcmAPUsx2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlNL6MKWUsx3"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/della-gatta-gene-gp2.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>Result of the fit of the Gaussian process model with the time\n",
        "scale parameter initialized to 2000 minutes.</i>\n",
        "\n",
        "Now we try a model initialized with a lower noise."
      ],
      "id": "JlNL6MKWUsx3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTQPxMjyUsx3"
      },
      "outputs": [],
      "source": [
        "m_full3 = GPy.models.GPRegression(x,yhat)\n",
        "m_full3.kern.lengthscale=20\n",
        "m_full3.likelihood.variance=0.001\n",
        "_ = m_full3.optimize() # Optimize parameters of covariance function"
      ],
      "id": "rTQPxMjyUsx3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mI7ie8ovUsx3"
      },
      "outputs": [],
      "source": [
        "import mlai.plot as plot"
      ],
      "id": "mI7ie8ovUsx3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLoNSFYIUsx3"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(figsize=plot.big_wide_figsize)\n",
        "plot.model_output(m_full3, scale=scale, offset=offset, ax=ax, xlabel='time/min', ylabel='expression', fontsize=20, portion=0.2)\n",
        "ax.set_xlim(xlim)\n",
        "ax.set_ylim(ylim)\n",
        "ax.set_title('log likelihood: {ll:.3}'.format(ll=m_full3.log_likelihood()), fontsize=20)\n",
        "mlai.write_figure(figure=fig,\n",
        "                  filename='./gp/della-gatta-gene-gp3.svg',\n",
        "                  transparent=True, frameon=True)"
      ],
      "id": "bLoNSFYIUsx3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPhbhBmHUsx3"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/della-gatta-gene-gp3.svg\" class=\"\" width=\"80%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>Result of the fit of the Gaussian process model with the\n",
        "noise initialized low (standard deviation 0.1) and the time scale\n",
        "parameter initialized to 20 minutes.</i>"
      ],
      "id": "uPhbhBmHUsx3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3AIu_uQUsx3"
      },
      "outputs": [],
      "source": [
        "import mlai.plot as plot"
      ],
      "id": "U3AIu_uQUsx3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcWxFml9Usx3"
      },
      "outputs": [],
      "source": [
        "plot.multiple_optima(diagrams='./gp')"
      ],
      "id": "YcWxFml9Usx3"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDlXaqfRUsx4"
      },
      "source": [
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/multiple-optima000.svg\" class=\"\" width=\"50%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i></i>\n",
        "\n",
        "<!--\n",
        "\n",
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/multiple-optima001.svg\" class=\"\" width=\"\" style=\"vertical-align:middle;\">-->"
      ],
      "id": "nDlXaqfRUsx4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olbj5kb8Usx4"
      },
      "source": [
        "## Example: Prediction of Malaria Incidence in Uganda\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_health/includes/malaria-gp.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_health/includes/malaria-gp.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "\\\\martinMubangiziPicture{15%}\\\\ricardoAndradePachecoPicture{15%}\\\\johnQuinnPicture{15%}\n",
        "\n",
        "As an example of using Gaussian process models within the full pipeline\n",
        "from data to decsion, we’ll consider the prediction of Malaria incidence\n",
        "in Uganda. For the purposes of this study malaria reports come in two\n",
        "forms, HMIS reports from health centres and Sentinel data, which is\n",
        "curated by the WHO. There are limited sentinel sites and many HMIS\n",
        "sites.\n",
        "\n",
        "The work is from Ricardo Andrade Pacheco’s PhD thesis, completed in\n",
        "collaboration with John Quinn and Martin Mubangizi (Andrade-Pacheco et\n",
        "al., 2014; Mubangizi et al., 2014). John and Martin were initally from\n",
        "the AI-DEV group from the University of Makerere in Kampala and more\n",
        "latterly they were based at UN Global Pulse in Kampala. You can see the\n",
        "work summarized on the UN Global Pulse [disease outbreaks project site\n",
        "here](https://diseaseoutbreaks.unglobalpulse.net/uganda/).\n",
        "\n",
        "-   See [UN Global Pulse Disease Outbreaks\n",
        "    Site](https://diseaseoutbreaks.unglobalpulse.net/uganda/)\n",
        "\n",
        "Malaria data is spatial data. Uganda is split into districts, and health\n",
        "reports can be found for each district. This suggests that models such\n",
        "as conditional random fields could be used for spatial modelling, but\n",
        "there are two complexities with this. First of all, occasionally\n",
        "districts split into two. Secondly, sentinel sites are a specific\n",
        "location within a district, such as Nagongera which is a sentinel site\n",
        "based in the Tororo district.\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//health/uganda-districts-2006.png\" style=\"width:50%\">\n",
        "\n",
        "Figure: <i>Ugandan districts. Data SRTM/NASA from\n",
        "<https://dds.cr.usgs.gov/srtm/version2_1>.</i>\n",
        "\n",
        "(Andrade-Pacheco et al., 2014; Mubangizi et al., 2014)\n",
        "\n",
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//health/Kapchorwa_District_in_Uganda.svg\" class=\"\" width=\"50%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>The Kapchorwa District, home district of Stephen\n",
        "Kiprotich.</i>\n",
        "\n",
        "Stephen Kiprotich, the 2012 gold medal winner from the London Olympics,\n",
        "comes from Kapchorwa district, in eastern Uganda, near the border with\n",
        "Kenya.\n",
        "\n",
        "The common standard for collecting health data on the African continent\n",
        "is from the Health management information systems (HMIS). However, this\n",
        "data suffers from missing values (Gething et al., 2006) and diagnosis of\n",
        "diseases like typhoid and malaria may be confounded.\n",
        "\n",
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//health/Tororo_District_in_Uganda.svg\" class=\"\" width=\"50%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>The Tororo district, where the sentinel site, Nagongera, is\n",
        "located.</i>\n",
        "\n",
        "[World Health Organization Sentinel Surveillance\n",
        "systems](https://www.who.int/immunization/monitoring_surveillance/burden/vpd/surveillance_type/sentinel/en/)\n",
        "are set up “when high-quality data are needed about a particular disease\n",
        "that cannot be obtained through a passive system.” Several sentinel\n",
        "sites give accurate assessment of malaria disease levels in Uganda,\n",
        "including a site in Nagongera.\n",
        "\n",
        "<img class=\"negate\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//health/sentinel_nagongera.png\" style=\"width:100%\">\n",
        "\n",
        "Figure: <i>Sentinel and HMIS data along with rainfall and temperature\n",
        "for the Nagongera sentinel station in the Tororo district.</i>\n",
        "\n",
        "In collaboration with the AI Research Group at Makerere we chose to\n",
        "investigate whether Gaussian process models could be used to assimilate\n",
        "information from these two different sources of disease informaton.\n",
        "Further, we were interested in whether local information on rainfall and\n",
        "temperature could be used to improve malaria estimates.\n",
        "\n",
        "The aim of the project was to use WHO Sentinel sites, alongside rainfall\n",
        "and temperature, to improve predictions from HMIS data of levels of\n",
        "malaria.\n",
        "\n",
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//health/Mubende_District_in_Uganda.svg\" class=\"\" width=\"50%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>The Mubende District.</i>\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//health/mubende.png\" style=\"width:80%\">\n",
        "\n",
        "Figure: <i>Prediction of malaria incidence in Mubende.</i>\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gpss/1157497_513423392066576_1845599035_n.jpg\" style=\"width:80%\">\n",
        "\n",
        "Figure: <i>The project arose out of the Gaussian process summer school\n",
        "held at Makerere in Kampala in 2013. The school led, in turn, to the\n",
        "Data Science Africa initiative.</i>"
      ],
      "id": "olbj5kb8Usx4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXHT0O2QUsx4"
      },
      "source": [
        "## Early Warning Systems\n",
        "\n",
        "<img src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//health/Kabarole_District_in_Uganda.svg\" class=\"\" width=\"50%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "Figure: <i>The Kabarole district in Uganda.</i>\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//health/kabarole.gif\" style=\"width:100%\">\n",
        "\n",
        "Figure: <i>Estimate of the current disease situation in the Kabarole\n",
        "district over time. Estimate is constructed with a Gaussian process with\n",
        "an additive covariance funciton.</i>\n",
        "\n",
        "Health monitoring system for the Kabarole district. Here we have fitted\n",
        "the reports with a Gaussian process with an additive covariance\n",
        "function. It has two components, one is a long time scale component (in\n",
        "red above) the other is a short time scale component (in blue).\n",
        "\n",
        "Monitoring proceeds by considering two aspects of the curve. Is the blue\n",
        "line (the short term report signal) above the red (which represents the\n",
        "long term trend? If so we have higher than expected reports. If this is\n",
        "the case *and* the gradient is still positive (i.e. reports are going\n",
        "up) we encode this with a *red* color. If it is the case and the\n",
        "gradient of the blue line is negative (i.e. reports are going down) we\n",
        "encode this with an *amber* color. Conversely, if the blue line is below\n",
        "the red *and* decreasing, we color *green*. On the other hand if it is\n",
        "below red but increasing, we color *yellow*.\n",
        "\n",
        "This gives us an early warning system for disease. Red is a bad\n",
        "situation getting worse, amber is bad, but improving. Green is good and\n",
        "getting better and yellow good but degrading.\n",
        "\n",
        "Finally, there is a gray region which represents when the scale of the\n",
        "effect is small.\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//health/monitor.gif\" style=\"width:50%\">\n",
        "\n",
        "Figure: <i>The map of Ugandan districts with an overview of the Malaria\n",
        "situation in each district.</i>\n",
        "\n",
        "These colors can now be observed directly on a spatial map of the\n",
        "districts to give an immediate impression of the current status of the\n",
        "disease across the country."
      ],
      "id": "HXHT0O2QUsx4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhXMvsplUsx4"
      },
      "source": [
        "## Additive Covariance\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_kern/includes/add-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/add-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
      ],
      "id": "dhXMvsplUsx4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ms61gimUsx4"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "9ms61gimUsx4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Kex-4NMUsx5"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.Kernel"
      ],
      "id": "1Kex-4NMUsx5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qB3QDX2EUsx5"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "qB3QDX2EUsx5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k76iG8bzUsx5"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.linear_cov"
      ],
      "id": "k76iG8bzUsx5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDizkaNdUsx5"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "DDizkaNdUsx5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eK8Wmr3fUsx5"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.eq_cov"
      ],
      "id": "eK8Wmr3fUsx5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FDZmMNqUsx5"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "6FDZmMNqUsx5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HD2HSDv2Usx5"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.add_cov"
      ],
      "id": "HD2HSDv2Usx5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzAmv6ELUsx6"
      },
      "outputs": [],
      "source": [
        "kernel = Kernel(function=add_cov,\n",
        "                     name='Additive',\n",
        "                     shortname='add',\n",
        "                     formula='\\kernelScalar_f(\\inputVector, \\inputVector^\\prime) = \\kernelScalar_g(\\inputVector, \\inputVector^\\prime) + \\kernelScalar_h(\\inputVector, \\inputVector^\\prime)',\n",
        "                     kerns=[linear_cov, eq_cov],\n",
        "                     kern_args=[{'variance': 25}, {'lengthscale' : 0.2}])"
      ],
      "id": "IzAmv6ELUsx6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zwOe0qBUsx6"
      },
      "outputs": [],
      "source": [
        "import mlai.plot as plot"
      ],
      "id": "4zwOe0qBUsx6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42fz9lTCUsx6"
      },
      "outputs": [],
      "source": [
        "plot.covariance_func(kernel=kernel, diagrams='./kern/')"
      ],
      "id": "42fz9lTCUsx6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9d_H9OLUsx6"
      },
      "source": [
        "An additive covariance function is derived from considering the result\n",
        "of summing two Gaussian processes together. If the first Gaussian\n",
        "process is $g(\\cdot)$, governed by covariance $k_g(\\cdot, \\cdot)$ and\n",
        "the second process is $h(\\cdot)$, governed by covariance\n",
        "$k_h(\\cdot, \\cdot)$ then the combined process\n",
        "$f(\\cdot) = g(\\cdot) + h(\\cdot)$ is govererned by a covariance function,\n",
        "$$\n",
        "k_f(\\mathbf{ x}, \\mathbf{ x}^\\prime) = k_g(\\mathbf{ x}, \\mathbf{ x}^\\prime) + k_h(\\mathbf{ x}, \\mathbf{ x}^\\prime)\n",
        "$$\n",
        "\n",
        "<center>\n",
        "\n",
        "$$k_f(\\mathbf{ x}, \\mathbf{ x}^\\prime) = k_g(\\mathbf{ x}, \\mathbf{ x}^\\prime) + k_h(\\mathbf{ x}, \\mathbf{ x}^\\prime)$$\n",
        "\n",
        "</center>\n",
        "<table>\n",
        "<tr>\n",
        "<td width=\"45%\">\n",
        "\n",
        "<img src=\"https://github.com/mlatcl/mlfc/blob/gh-pages/slides/diagrams/kern/add_covariance.svg?raw=1\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "</td>\n",
        "<td width=\"45%\">\n",
        "\n",
        "<img class=\"negate\" src=\"https://github.com/mlatcl/mlfc/blob/gh-pages/slides/diagrams/kern/add_covariance.gif?raw=1\" style=\"width:100%\">\n",
        "\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "Figure: <i>An additive covariance function formed by combining a linear\n",
        "and an exponentiated quadratic covariance functions.</i>"
      ],
      "id": "P9d_H9OLUsx6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q4FAL9IUsx7"
      },
      "source": [
        "## Analysis of US Birth Rates\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/bda-forecasting.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/bda-forecasting.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "\\\\akiVehtariPicture{15%}\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//ml/bialik-fridaythe13th-1.png\" style=\"width:70%\">\n",
        "\n",
        "Figure: <i>This is a retrospective analysis of US births by Aki Vehtari.\n",
        "The challenges of forecasting. Even with seasonal and weekly effects\n",
        "removed there are significant effects on holidays, weekends, etc.</i>\n",
        "\n",
        "There’s a nice analysis of US birth rates by Gaussian processes with\n",
        "additive covariances in Gelman et al. (2013). A combination of\n",
        "covariance functions are used to take account of weekly and yearly\n",
        "trends. The analysis is summarized on the cover of the book.\n",
        "\n",
        "<table>\n",
        "<tr>\n",
        "<td width=\"50%\">\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//ml/bda_cover_1.png\" style=\"width:80%\">\n",
        "\n",
        "</td>\n",
        "<td width=\"50%\">\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//ml/bda_cover.png\" style=\"width:80%\">\n",
        "\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "Figure: <i>Two different editions of Bayesian Data Analysis (Gelman et\n",
        "al., 2013).</i>"
      ],
      "id": "2Q4FAL9IUsx7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzpXCJ8uUsx7"
      },
      "source": [
        "## Basis Function Covariance\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_kern/includes/basis-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/basis-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "The fixed basis function covariance just comes from the properties of a\n",
        "multivariate Gaussian, if we decide $$\n",
        "\\mathbf{ f}=\\boldsymbol{ \\Phi}\\mathbf{ w}\n",
        "$$ and then we assume $$\n",
        "\\mathbf{ w}\\sim \\mathcal{N}\\left(\\mathbf{0},\\alpha\\mathbf{I}\\right)\n",
        "$$ then it follows from the properties of a multivariate Gaussian that\n",
        "$$\n",
        "\\mathbf{ f}\\sim \\mathcal{N}\\left(\\mathbf{0},\\alpha\\boldsymbol{ \\Phi}\\boldsymbol{ \\Phi}^\\top\\right)\n",
        "$$ meaning that the vector of observations from the function is jointly\n",
        "distributed as a Gaussian process and the covariance matrix is\n",
        "$\\mathbf{K}= \\alpha\\boldsymbol{ \\Phi}\\boldsymbol{ \\Phi}^\\top$, each\n",
        "element of the covariance matrix can then be found as the inner product\n",
        "between two rows of the basis funciton matrix."
      ],
      "id": "nzpXCJ8uUsx7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVNic7QvUsx7"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "CVNic7QvUsx7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGNQvwPCUsx8"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.basis_cov"
      ],
      "id": "qGNQvwPCUsx8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEu9CXVvUsx8"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "fEu9CXVvUsx8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGH98bg9Usx8"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.radial"
      ],
      "id": "lGH98bg9Usx8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkbbH4jVUsx8"
      },
      "outputs": [],
      "source": [
        "import mlai.plot as plot\n",
        "import mlai\n",
        "import numpy as np"
      ],
      "id": "mkbbH4jVUsx8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P07RhxTBUsx9"
      },
      "outputs": [],
      "source": [
        "basis = mlai.Basis(function=radial,\n",
        "                   number=3,\n",
        "                   data_limits=[-0.5, 0.5],\n",
        "                   width=0.125)\n",
        "kernel = mlai.Kernel(function=basis_cov,\n",
        "                     name='Basis',\n",
        "                     shortname='basis',\n",
        "                     formula='\\kernel(\\inputVector, \\inputVector^\\prime) = \\basisVector(\\inputVector)^\\top \\basisVector(\\inputVector^\\prime)',\n",
        "                     basis=basis)\n",
        "\n",
        "plot.covariance_func(kernel, diagrams='./kern/')"
      ],
      "id": "P07RhxTBUsx9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sud7zvpwUsx9"
      },
      "source": [
        "<center>\n",
        "\n",
        "$$k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\boldsymbol{ \\phi}(\\mathbf{ x})^\\top \\boldsymbol{ \\phi}(\\mathbf{ x}^\\prime)$$\n",
        "\n",
        "</center>\n",
        "<table>\n",
        "<tr>\n",
        "<td width=\"45%\">\n",
        "\n",
        "<img src=\"https://github.com/mlatcl/mlfc/blob/gh-pages/slides/diagrams/kern/basis_covariance.svg?raw=1\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "</td>\n",
        "<td width=\"45%\">\n",
        "\n",
        "<img class=\"negate\" src=\"https://github.com/mlatcl/mlfc/blob/gh-pages/slides/diagrams/kern/basis_covariance.gif?raw=1\" style=\"width:100%\">\n",
        "\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "Figure: <i>A covariance function based on a non-linear basis given by\n",
        "$\\boldsymbol{ \\phi}(\\mathbf{ x})$.</i>"
      ],
      "id": "Sud7zvpwUsx9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ronsiR6Usx9"
      },
      "source": [
        "## Brownian Covariance\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_kern/includes/brownian-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/brownian-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
      ],
      "id": "8ronsiR6Usx9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3vxy2BtUsx9"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "A3vxy2BtUsx9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPbmXXbPUsx-"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.brownian_cov"
      ],
      "id": "TPbmXXbPUsx-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFUvR6TYUsx-"
      },
      "outputs": [],
      "source": [
        "import mlai.plot as plot\n",
        "import mlai\n",
        "import numpy as np"
      ],
      "id": "PFUvR6TYUsx-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pc_qQU9zUsx-"
      },
      "outputs": [],
      "source": [
        "t=np.linspace(0, 2, 200)[:, np.newaxis]\n",
        "kernel = mlai.Kernel(function=brownian_cov,\n",
        "                     name='Brownian',\n",
        "                     formula='\\kernelScalar(t, t^\\prime)=\\alpha \\min(t, t^\\prime)',\n",
        "                     shortname='brownian')\n",
        "plot.covariance_func(kernel, t, diagrams='./kern/')"
      ],
      "id": "pc_qQU9zUsx-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjceFY-jUsx-"
      },
      "source": [
        "Brownian motion is also a Gaussian process. It follows a Gaussian random\n",
        "walk, with diffusion occuring at each time point driven by a Gaussian\n",
        "input. This implies it is both Markov and Gaussian. The covariance\n",
        "function for Brownian motion has the form $$\n",
        "k(t, t^\\prime)=\\alpha \\min(t, t^\\prime)\n",
        "$$\n",
        "\n",
        "<center>\n",
        "\n",
        "$$k(t, t^\\prime)=\\alpha \\min(t, t^\\prime)$$\n",
        "\n",
        "</center>\n",
        "<table>\n",
        "<tr>\n",
        "<td width=\"45%\">\n",
        "\n",
        "<img src=\"https://github.com/mlatcl/mlfc/blob/gh-pages/slides/diagrams/kern/brownian_covariance.svg?raw=1\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "</td>\n",
        "<td width=\"45%\">\n",
        "\n",
        "<img class=\"negate\" src=\"https://github.com/mlatcl/mlfc/blob/gh-pages/slides/diagrams/kern/brownian_covariance.gif?raw=1\" style=\"width:100%\">\n",
        "\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "Figure: <i>Brownian motion covariance function.</i>"
      ],
      "id": "mjceFY-jUsx-"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCecQyi7Usx-"
      },
      "source": [
        "## MLP Covariance\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_kern/includes/mlp-covariance.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_kern/includes/mlp-covariance.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>"
      ],
      "id": "mCecQyi7Usx-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFmbhcnKUsx-"
      },
      "outputs": [],
      "source": [
        "import mlai"
      ],
      "id": "iFmbhcnKUsx-"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uFPBBOV9Usx_"
      },
      "outputs": [],
      "source": [
        "%load -n mlai.mlp_cov"
      ],
      "id": "uFPBBOV9Usx_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2wlDGlYUsx_"
      },
      "outputs": [],
      "source": [
        "import mlai.plot as plot\n",
        "import mlai\n",
        "import numpy as np"
      ],
      "id": "P2wlDGlYUsx_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDapR-VeUsx_"
      },
      "outputs": [],
      "source": [
        "kernel = mlai.Kernel(function=mlp_cov,\n",
        "                     name='Multilayer Perceptron',\n",
        "                     shortname='mlp',\n",
        "                     formula='\\kernelScalar(\\inputVector, \\inputVector^\\prime) = \\alpha \\arcsin\\left(\\frac{w \\inputVector^\\top \\inputVector^\\prime + b}{\\sqrt{\\left(w \\inputVector^\\top \\inputVector + b + 1\\right)\\left(w \\left.\\inputVector^\\prime\\right.^\\top \\inputVector^\\prime + b + 1\\right)}}\\right)',\n",
        "                     w=5, b=0.5)\n",
        "\n",
        "plot.covariance_func(kernel, diagrams='./kern/')"
      ],
      "id": "qDapR-VeUsx_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHcQ7jUXUsx_"
      },
      "source": [
        "The multi-layer perceptron (MLP) covariance, also known as the neural\n",
        "network covariance or the arcsin covariance, is derived by considering\n",
        "the infinite limit of a neural network.\n",
        "\n",
        "<center>\n",
        "\n",
        "$$k(\\mathbf{ x}, \\mathbf{ x}^\\prime) = \\alpha \\arcsin\\left(\\frac{w \\mathbf{ x}^\\top \\mathbf{ x}^\\prime + b}{\\sqrt{\\left(w \\mathbf{ x}^\\top \\mathbf{ x}+ b + 1\\right)\\left(w \\left.\\mathbf{ x}^\\prime\\right.^\\top \\mathbf{ x}^\\prime + b + 1\\right)}}\\right)$$\n",
        "\n",
        "</center>\n",
        "<table>\n",
        "<tr>\n",
        "<td width=\"45%\">\n",
        "\n",
        "<img src=\"https://github.com/mlatcl/mlfc/blob/gh-pages/slides/diagrams/kern/mlp_covariance.svg?raw=1\" class=\"\" width=\"100%\" style=\"vertical-align:middle;\">\n",
        "\n",
        "</td>\n",
        "<td width=\"45%\">\n",
        "\n",
        "<img class=\"negate\" src=\"https://github.com/mlatcl/mlfc/blob/gh-pages/slides/diagrams/kern/mlp_covariance.gif?raw=1\" style=\"width:100%\">\n",
        "\n",
        "</td>\n",
        "</tr>\n",
        "</table>\n",
        "\n",
        "Figure: <i>The multi-layer perceptron covariance function. This is\n",
        "derived by considering the infinite limit of a neural network with\n",
        "probit activation functions.</i>"
      ],
      "id": "fHcQ7jUXUsx_"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hm8Gmk8UsyA"
      },
      "source": [
        "## GPSS: Gaussian Process Summer School\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-summer-school.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_gp/includes/gp-summer-school.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "If you’re interested in finding out more about Gaussian processes, you\n",
        "can attend the Gaussian process summer school, or view the lectures and\n",
        "material on line. Details of the school, future events and past events\n",
        "can be found at the website <http://gpss.cc>."
      ],
      "id": "_hm8Gmk8UsyA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t11CRHblUsyA"
      },
      "outputs": [],
      "source": [
        "%pip install gpy"
      ],
      "id": "t11CRHblUsyA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtBw2vlSUsyA"
      },
      "source": [
        "## GPy: A Gaussian Process Framework in Python\n",
        "\n",
        "<span class=\"editsection-bracket\" style=\"\">\\[</span><span\n",
        "class=\"editsection\"\n",
        "style=\"\"><a href=\"https://github.com/lawrennd/snippets/edit/main/_software/includes/gpy-software.md\" target=\"_blank\" onclick=\"ga('send', 'event', 'Edit Page', 'Edit', 'https://github.com/lawrennd/snippets/edit/main/_software/includes/gpy-software.md', 13);\">edit</a></span><span class=\"editsection-bracket\" style=\"\">\\]</span>\n",
        "\n",
        "Gaussian processes are a flexible tool for non-parametric analysis with\n",
        "uncertainty. The GPy software was started in Sheffield to provide a easy\n",
        "to use interface to GPs. One which allowed the user to focus on the\n",
        "modelling rather than the mathematics.\n",
        "\n",
        "<img class=\"\" src=\"https://mlatcl.github.io/mlfc/./slides/diagrams//gp/gpy.png\" style=\"width:70%\">\n",
        "\n",
        "Figure: <i>GPy is a BSD licensed software code base for implementing\n",
        "Gaussian process models in Python. It is designed for teaching and\n",
        "modelling. We welcome contributions which can be made through the GitHub\n",
        "repository <https://github.com/SheffieldML/GPy></i>\n",
        "\n",
        "GPy is a BSD licensed software code base for implementing Gaussian\n",
        "process models in python. This allows GPs to be combined with a wide\n",
        "variety of software libraries.\n",
        "\n",
        "The software itself is available on\n",
        "[GitHub](https://github.com/SheffieldML/GPy) and the team welcomes\n",
        "contributions.\n",
        "\n",
        "The aim for GPy is to be a probabilistic-style programming language,\n",
        "i.e., you specify the model rather than the algorithm. As well as a\n",
        "large range of covariance functions the software allows for non-Gaussian\n",
        "likelihoods, multivariate outputs, dimensionality reduction and\n",
        "approximations for larger data sets.\n",
        "\n",
        "The documentation for GPy can be found\n",
        "[here](https://gpy.readthedocs.io/en/latest/)."
      ],
      "id": "wtBw2vlSUsyA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkPPpxUZUsyA"
      },
      "source": [
        "## Thanks!\n",
        "\n",
        "For more information on these subjects and more you might want to check\n",
        "the following resources.\n",
        "\n",
        "-   company: [Trent AI](https://trent.ai)\n",
        "-   book: [The Atomic\n",
        "    Human](https://www.penguin.co.uk/books/455130/the-atomic-human-by-lawrence-neil-d/9780241625248)\n",
        "-   twitter: [@lawrennd](https://twitter.com/lawrennd)\n",
        "-   podcast: [The Talking Machines](http://thetalkingmachines.com)\n",
        "-   newspaper: [Guardian Profile\n",
        "    Page](http://www.theguardian.com/profile/neil-lawrence)\n",
        "-   blog:\n",
        "    [http://inverseprobability.com](http://inverseprobability.com/blog.html)"
      ],
      "id": "nkPPpxUZUsyA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0070EKAUsyA"
      },
      "source": [
        "::: {.cell .markdown}\n",
        "\n",
        "## References\n",
        "\n",
        "Andrade-Pacheco, R., Mubangizi, M., Quinn, J., Lawrence, N.D., 2014.\n",
        "Consistent mapping of government malaria records across a changing\n",
        "territory delimitation. Malaria Journal 13.\n",
        "<https://doi.org/10.1186/1475-2875-13-S1-P5>\n",
        "\n",
        "Della Gatta, G., Bansal, M., Ambesi-Impiombato, A., Antonini, D.,\n",
        "Missero, C., Bernardo, D. di, 2008. Direct targets of the TRP63\n",
        "transcription factor revealed by a combination of gene expression\n",
        "profiling and reverse engineering. Genome Research 18, 939–948.\n",
        "<https://doi.org/10.1101/gr.073601.107>\n",
        "\n",
        "Gelman, A., Carlin, J.B., Stern, H.S., Dunson, D.B., Vehtari, A., Rubin,\n",
        "D.B., 2013. Bayesian data analysis, 3rd ed. Chapman; Hall.\n",
        "\n",
        "Gething, P.W., Noor, A.M., Gikandi, P.W., Ogara, E.A.A., Hay, S.I.,\n",
        "Nixon, M.S., Snow, R.W., Atkinson, P.M., 2006. Improving imperfect data\n",
        "from health management information systems in Africa using space–time\n",
        "geostatistics. PLoS Medicine 3.\n",
        "<https://doi.org/10.1371/journal.pmed.0030271>\n",
        "\n",
        "Kalaitzis, A.A., Lawrence, N.D., 2011. A simple approach to ranking\n",
        "differentially expressed gene expression time courses through Gaussian\n",
        "process regression. BMC Bioinformatics 12.\n",
        "<https://doi.org/10.1186/1471-2105-12-180>\n",
        "\n",
        "MacKay, D.J.C., 1992. Bayesian methods for adaptive models (PhD thesis).\n",
        "California Institute of Technology.\n",
        "\n",
        "Mubangizi, M., Andrade-Pacheco, R., Smith, M.T., Quinn, J., Lawrence,\n",
        "N.D., 2014. Malaria surveillance with multiple data sources using\n",
        "Gaussian process models, in: 1st International Conference on the Use of\n",
        "Mobile ICT in Africa.\n",
        "\n",
        "Neal, R.M., 1994. Bayesian learning for neural networks (PhD thesis).\n",
        "Dept. of Computer Science, University of Toronto."
      ],
      "id": "L0070EKAUsyA"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  }
}